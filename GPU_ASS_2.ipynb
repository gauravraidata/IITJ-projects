{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNneNaVNJYSxRv3jn2lx9U5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravraidata/IITJ-projects/blob/main/GPU_ASS_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse, time, os, math, sys\n",
        "from typing import Dict, List, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cupy as cp\n",
        "import cupyx.scipy.sparse as cpx_sparse"
      ],
      "metadata": {
        "id": "zM_-DE_xmFAu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_item_session(csv_path: str, country: str = None):\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"CSV not found: {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
        "    required = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Quantity\", \"UnitPrice\"]\n",
        "    for c in required:\n",
        "        if c not in df.columns:\n",
        "            raise RuntimeError(f\"Required column '{c}' not found in CSV\")\n",
        "\n",
        "    df = df.dropna(subset=required)\n",
        "    df = df[~df[\"InvoiceNo\"].astype(str).str.startswith(\"C\")]\n",
        "    df = df[df[\"Quantity\"] > 0]\n",
        "    df = df[df[\"UnitPrice\"] > 0.0]\n",
        "    if country and \"Country\" in df.columns:\n",
        "        df = df[df[\"Country\"] == country]\n",
        "\n",
        "    df[\"StockCode\"] = df[\"StockCode\"].astype(str)\n",
        "    unique_products = pd.Series(df[\"StockCode\"].unique())\n",
        "    prod_to_idx = {p: i for i, p in enumerate(unique_products)}\n",
        "    df[\"item_idx\"] = df[\"StockCode\"].map(prod_to_idx)\n",
        "\n",
        "    df[\"InvoiceNo\"] = df[\"InvoiceNo\"].astype(str)\n",
        "    unique_invoices = pd.Series(df[\"InvoiceNo\"].unique())\n",
        "    inv_to_idx = {inv: i for i, inv in enumerate(unique_invoices)}\n",
        "    df[\"session_idx\"] = df[\"InvoiceNo\"].map(inv_to_idx)\n",
        "\n",
        "    df_unique = df.drop_duplicates(subset=[\"session_idx\", \"item_idx\"])\n",
        "\n",
        "    rows = df_unique[\"item_idx\"].to_numpy(dtype=np.int32)\n",
        "    cols = df_unique[\"session_idx\"].to_numpy(dtype=np.int32)\n",
        "    data = (np.ones_like(rows, dtype=np.int8)).astype(np.int8)\n",
        "\n",
        "    num_items = len(unique_products)\n",
        "    num_sessions = len(unique_invoices)\n",
        "\n",
        "    item_session = sparse.csr_matrix((data, (rows, cols)), shape=(num_items, num_sessions), dtype=np.int32)\n",
        "\n",
        "    item_meta: Dict[int, Dict] = {}\n",
        "    for idx, sub in df.groupby(\"item_idx\"):\n",
        "        desc = sub[\"Description\"].mode().iloc[0] if \"Description\" in sub else \"\"\n",
        "        item_meta[int(idx)] = {\"stock_code\": sub[\"StockCode\"].iloc[0], \"description\": str(desc)}\n",
        "\n",
        "    return item_session, item_meta, num_sessions"
      ],
      "metadata": {
        "id": "CuYOnWZImYLH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scipy_csr_to_cupy_csr(scipy_csr: sparse.csr_matrix):\n",
        "    coo = scipy_csr.tocoo()\n",
        "    data_cp = cp.asarray(coo.data, dtype=cp.float32)\n",
        "    row_cp = cp.asarray(coo.row)\n",
        "    col_cp = cp.asarray(coo.col)\n",
        "    cupy_coo = cpx_sparse.coo_matrix((data_cp, (row_cp, col_cp)), shape=scipy_csr.shape)\n",
        "    return cupy_coo.tocsr()"
      ],
      "metadata": {
        "id": "F11mhKMUmkzm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gpu_topk_all_items(item_session_cupy, k: int, batch_size: int = 64):\n",
        "    num_items = int(item_session_cupy.shape[0])\n",
        "\n",
        "    # diag: sessions containing item (on device)\n",
        "    diag_gpu = item_session_cupy.multiply(item_session_cupy).sum(axis=1).ravel().astype(cp.int32)\n",
        "    diag_host = cp.asnumpy(diag_gpu)\n",
        "\n",
        "    topk_idx_list = [None] * num_items\n",
        "    topk_scores_list = [None] * num_items\n",
        "\n",
        "    start_time = time.time()\n",
        "    sqrt_diag_gpu = cp.sqrt(cp.maximum(diag_gpu.astype(cp.float32), 1.0))\n",
        "    anchors = np.arange(num_items, dtype=np.int32)\n",
        "\n",
        "    for bstart in range(0, num_items, batch_size):\n",
        "        bend = min(bstart + batch_size, num_items)\n",
        "        batch_anchors = anchors[bstart:bend]\n",
        "        B = len(batch_anchors)\n",
        "\n",
        "        # slice rows and compute co-occurrence for the batch\n",
        "        batch_rows_sp = item_session_cupy[batch_anchors, :]\n",
        "        co_batch_sp = batch_rows_sp.dot(item_session_cupy.T)\n",
        "        co_batch_dense = co_batch_sp.toarray().astype(cp.float32)  # (B, N)\n",
        "\n",
        "        denom_matrix = sqrt_diag_gpu[cp.asarray(batch_anchors, dtype=cp.int32)].astype(cp.float32)[:, None] * sqrt_diag_gpu[None, :]\n",
        "\n",
        "        sim_batch = cp.where(denom_matrix > 0.0, co_batch_dense / denom_matrix, 0.0).astype(cp.float32)\n",
        "\n",
        "        # vectorized zero-out self positions (keep entirely on device)\n",
        "        sim_batch[cp.arange(B, dtype=cp.int32), cp.asarray(batch_anchors, dtype=cp.int32)] = 0.0\n",
        "\n",
        "        # per-row top-k (device)\n",
        "        if k >= num_items:\n",
        "            topk_idx_batch = cp.argsort(-sim_batch, axis=1)[:, :k]\n",
        "            topk_scores_batch = cp.take_along_axis(sim_batch, topk_idx_batch, axis=1)\n",
        "        else:\n",
        "            part_idx = cp.argpartition(-sim_batch, k, axis=1)[:, :k]\n",
        "            part_scores = cp.take_along_axis(sim_batch, part_idx, axis=1)\n",
        "            order = cp.argsort(-part_scores, axis=1)\n",
        "            topk_idx_batch = cp.take_along_axis(part_idx, order, axis=1)\n",
        "            topk_scores_batch = cp.take_along_axis(part_scores, order, axis=1)\n",
        "\n",
        "        # Transfer small B x k arrays to host\n",
        "        topk_idx_batch_host = cp.asnumpy(topk_idx_batch.astype(cp.int32))\n",
        "        topk_scores_batch_host = cp.asnumpy(topk_scores_batch.astype(cp.float32))\n",
        "\n",
        "        for local_r in range(B):\n",
        "            global_i = int(batch_anchors[local_r])\n",
        "            topk_idx_list[global_i] = topk_idx_batch_host[local_r].astype(np.int32)\n",
        "            topk_scores_list[global_i] = topk_scores_batch_host[local_r].astype(np.float32)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"[GPU batch] anchors {bstart}-{bend-1} processed (B={B}), elapsed={elapsed:.2f}s\")\n",
        "\n",
        "    gpu_elapsed = time.time() - start_time\n",
        "    return topk_idx_list, topk_scores_list, diag_host, gpu_elapsed"
      ],
      "metadata": {
        "id": "cDZwUESDmz9R"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cpu_topk_all_items(item_session_scipy, k: int):\n",
        "    num_items = item_session_scipy.shape[0]\n",
        "    diag = item_session_scipy.multiply(item_session_scipy).sum(axis=1).A1.astype(np.int32)\n",
        "    topk_idx_list = [None] * num_items\n",
        "    topk_scores_list = [None] * num_items\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_items):\n",
        "        row = item_session_scipy.getrow(i)\n",
        "        co_row_sp = row.dot(item_session_scipy.T)\n",
        "        co_row = co_row_sp.toarray().ravel().astype(np.float32)\n",
        "\n",
        "        denom = math.sqrt(diag[i]) * np.sqrt(np.maximum(diag, 1.0))\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            sim_row = np.where(denom > 0, co_row / denom, 0.0).astype(np.float32)\n",
        "        sim_row[i] = 0.0\n",
        "\n",
        "        if k >= sim_row.size:\n",
        "            idx = np.argsort(-sim_row)[:k]\n",
        "        else:\n",
        "            part = np.argpartition(-sim_row, k)[:k]\n",
        "            idx = part[np.argsort(-sim_row[part])]\n",
        "\n",
        "        topk_idx_list[i] = idx.astype(np.int32)\n",
        "        topk_scores_list[i] = sim_row[idx].astype(np.float32)\n",
        "\n",
        "        if (i + 1) % 500 == 0 or (i + 1) == num_items:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"[CPU] completed {i+1}/{num_items} items, elapsed={elapsed:.2f}s\")\n",
        "\n",
        "    cpu_elapsed = time.time() - start_time\n",
        "    return topk_idx_list, topk_scores_list, diag, cpu_elapsed\n"
      ],
      "metadata": {
        "id": "OuKcASqKnSnA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_anchor_table(anchor_idx: int, topk_idx_list: List[np.ndarray], topk_scores_list: List[np.ndarray],\n",
        "                       item_session_scipy: sparse.csr_matrix, diag: np.ndarray, item_meta: Dict[int, Dict],\n",
        "                       num_sessions: int) -> pd.DataFrame:\n",
        "    co_row_sp = item_session_scipy.getrow(anchor_idx).dot(item_session_scipy.T)\n",
        "    co_row = co_row_sp.toarray().ravel().astype(np.int32)\n",
        "    denom = math.sqrt(diag[anchor_idx]) * np.sqrt(np.maximum(diag, 1.0))\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        sim_exact = np.where(denom > 0.0, co_row.astype(np.float32) / denom, 0.0).astype(np.float32)\n",
        "    sim_exact[anchor_idx] = 0.0\n",
        "\n",
        "    top_idx = topk_idx_list[anchor_idx]\n",
        "    rows = []\n",
        "    for rank, other in enumerate(top_idx, start=1):\n",
        "        co_cnt = int(co_row[int(other)])\n",
        "        sim_score = float(sim_exact[int(other)])\n",
        "        lift = 0.0\n",
        "        if diag[anchor_idx] > 0 and diag[int(other)] > 0:\n",
        "            p_ab = co_cnt / float(num_sessions)\n",
        "            p_a = diag[anchor_idx] / float(num_sessions)\n",
        "            p_b = diag[int(other)] / float(num_sessions)\n",
        "            lift = p_ab / (p_a * p_b) if (p_a * p_b) > 0 else 0.0\n",
        "        rows.append({\n",
        "            \"rank\": rank,\n",
        "            \"item_index\": int(other),\n",
        "            \"stock_code\": item_meta[int(other)][\"stock_code\"] if int(other) in item_meta else \"\",\n",
        "            \"description\": item_meta[int(other)][\"description\"] if int(other) in item_meta else \"\",\n",
        "            \"cooccurrence\": co_cnt,\n",
        "            \"similarity\": sim_score,\n",
        "            \"lift\": lift,\n",
        "            \"sessions_with_other\": int(diag[int(other)])\n",
        "        })\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "nPc6FcDWnfBb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_timing_inline(cpu_time, gpu_transfer, gpu_compute):\n",
        "    gpu_total = gpu_transfer + gpu_compute\n",
        "    labels = [\"CPU (SciPy) per-row\", \"GPU transfer\", \"GPU compute\", \"GPU total\"]\n",
        "    times = [cpu_time, gpu_transfer, gpu_compute, gpu_total]\n",
        "    plt.figure(figsize=(8,4))\n",
        "    bars = plt.bar(labels, times)\n",
        "    plt.ylabel(\"Seconds\")\n",
        "    plt.title(\"CPU vs GPU timing breakdown\")\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, h + 0.3, f\"{h:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xJylGNi_nmVF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_anchor_tables_and_csvs(anchor_idx, recs_anchor_gpu, recs_anchor_cpu, save_prefix=\"anchor_recs\"):\n",
        "    gpu_csv = f\"{save_prefix}_gpu.csv\"\n",
        "    cpu_csv = f\"{save_prefix}_cpu.csv\"\n",
        "    recs_anchor_gpu.to_csv(gpu_csv, index=False)\n",
        "    recs_anchor_cpu.to_csv(cpu_csv, index=False)\n",
        "    print(f\"Saved anchor tables: {gpu_csv}, {cpu_csv}\")"
      ],
      "metadata": {
        "id": "0NDtpD48n0WW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pipeline_explanation():\n",
        "    print(\"\\n=== GPU pipeline explanation & summary ===\")\n",
        "    print(\"1) Data ingestion & preprocessing (host): CSV -> pandas -> SciPy CSR.\")\n",
        "    print(\"2) Transfer to GPU: SciPy CSR -> CuPy CSR (single conversion).\")\n",
        "    print(\"3) Batched GPU compute:\")\n",
        "    print(\"   - For each batch: compute BxN cooccurrence, normalize (device), top-k (device), transfer BxK back.\")\n",
        "    print(\"4) CPU baseline: per-row sparse matmul + numpy top-k (highly optimized on CPU).\")\n",
        "    print(\"\\nWhy GPU can be slower than CPU sometimes: kernel-launch & allocation overhead for many tiny tasks.\")\n",
        "    print(\"Tune batch_size (e.g., 32/64/128) to amortize overhead; larger B uses more GPU memory but fewer launches.\")\n",
        "    print(\"==========================================\\n\")"
      ],
      "metadata": {
        "id": "MT6npCWsoPPe"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(argv=None):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--csv\", type=str, default=\"OnlineRetail_cached.csv\", help=\"Path to local CSV\")\n",
        "    parser.add_argument(\"--k\", type=int, default=10, help=\"Top-K\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"GPU batch size for anchors\")\n",
        "    parser.add_argument(\"--anchor_by\", choices=[\"most_popular\",\"random\",\"id\"], default=\"most_popular\")\n",
        "    parser.add_argument(\"--anchor_id\", type=int, default=None)\n",
        "    parser.add_argument(\"--country\", type=str, default=None)\n",
        "    parser.add_argument(\"--save_all\", action=\"store_true\", help=\"Save full recs CSVs\")\n",
        "    parser.add_argument(\"--inline_plot\", action=\"store_true\", help=\"Show timing plot inline (not saved)\")\n",
        "    args = parser.parse_args(argv)\n",
        "\n",
        "    csv_path = args.csv\n",
        "    k = args.k\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    print(\"STEP 1: Load dataset and build host CSR (SciPy).\")\n",
        "    t0 = time.time()\n",
        "    item_session_scipy, item_meta, num_sessions = load_item_session(csv_path, country=args.country)\n",
        "    t1 = time.time()\n",
        "    print(f\" loaded: items={item_session_scipy.shape[0]}, sessions={item_session_scipy.shape[1]}, time={t1-t0:.2f}s\")\n",
        "\n",
        "    print(\"\\nSTEP 2: Transfer CSR to GPU (CuPy).\")\n",
        "    t0 = time.time()\n",
        "    item_session_gpu = scipy_csr_to_cupy_csr(item_session_scipy)\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    t_transfer = time.time() - t0\n",
        "    print(f\" transfer time: {t_transfer:.2f}s\")\n",
        "\n",
        "    print(\"\\nSTEP 3: GPU compute top-K per item (batched).\")\n",
        "    t0 = time.time()\n",
        "    topk_idx_gpu, topk_scores_gpu, diag_gpu, t_gpu_compute = gpu_topk_all_items(item_session_gpu, k=k, batch_size=batch_size)\n",
        "    t_gpu_total = t_transfer + t_gpu_compute\n",
        "    print(f\" GPU total (transfer+compute): {t_gpu_total:.2f}s (compute only: {t_gpu_compute:.2f}s)\")\n",
        "\n",
        "    print(\"\\nSTEP 4: CPU baseline top-K per item (for comparison).\")\n",
        "    topk_idx_cpu, topk_scores_cpu, diag_cpu, t_cpu = cpu_topk_all_items(item_session_scipy, k=k)\n",
        "    print(f\" CPU total compute: {t_cpu:.2f}s\")\n",
        "\n",
        "    # choose anchor\n",
        "    if args.anchor_by == \"most_popular\":\n",
        "        anchor = int(np.argmax(diag_cpu))\n",
        "    elif args.anchor_by == \"random\":\n",
        "        anchor = int(np.random.default_rng(1).integers(0, item_session_scipy.shape[0]))\n",
        "    else:\n",
        "        if args.anchor_id is None:\n",
        "            raise ValueError(\"anchor_id required when anchor_by=='id'\")\n",
        "        anchor = args.anchor_id\n",
        "\n",
        "    anchor_stock = item_meta[anchor]['stock_code']\n",
        "    anchor_name  = item_meta[anchor]['description']\n",
        "\n",
        "    print(f\"\\nAnchor item index = {anchor}; \"\n",
        "          f\"stock_code = {anchor_stock}; \"\n",
        "          f\"description = {anchor_name}; \"\n",
        "          f\"sessions_with_anchor = {int(diag_cpu[anchor])}\")\n",
        "\n",
        "    # build anchor tables\n",
        "    recs_anchor_gpu = build_anchor_table(anchor, topk_idx_gpu, topk_scores_gpu, item_session_scipy, diag_gpu, item_meta, num_sessions)\n",
        "    recs_anchor_cpu = build_anchor_table(anchor, topk_idx_cpu, topk_scores_cpu, item_session_scipy, diag_cpu, item_meta, num_sessions)\n",
        "\n",
        "    print(\"\\nTop-K (GPU-derived):\")\n",
        "    print(recs_anchor_gpu.to_string(index=False))\n",
        "\n",
        "    print(\"\\nTop-K (CPU-derived):\")\n",
        "    print(recs_anchor_cpu.to_string(index=False))\n",
        "\n",
        "    # Example recommendations for 2 products (top-2 by popularity)\n",
        "    try:\n",
        "        top2 = list(np.argsort(-diag_cpu)[:2])\n",
        "        print(f\"\\n\\n=== Recommendation examples for 2 products (indexes): {top2} ===\")\n",
        "        for ex_anchor in top2:\n",
        "            ex_stock = item_meta[ex_anchor]['stock_code']\n",
        "            ex_name = item_meta[ex_anchor]['description']\n",
        "            print(f\"\\nExample Anchor {ex_anchor} (stock_code = {ex_stock}, description = {ex_name}, sessions = {int(diag_cpu[ex_anchor])})\")\n",
        "            ex_recs_gpu = build_anchor_table(ex_anchor, topk_idx_gpu, topk_scores_gpu, item_session_scipy, diag_gpu, item_meta, num_sessions)\n",
        "            ex_recs_cpu = build_anchor_table(ex_anchor, topk_idx_cpu, topk_scores_cpu, item_session_scipy, diag_cpu, item_meta, num_sessions)\n",
        "            print(\"\\nGPU-derived top-5:\")\n",
        "            print(ex_recs_gpu.head(5).to_string(index=False))\n",
        "            print(\"\\nCPU-derived top-5:\")\n",
        "            print(ex_recs_cpu.head(5).to_string(index=False))\n",
        "    except Exception as e:\n",
        "        print(\"Could not produce 2-product examples:\", e)\n",
        "\n",
        "    # Save anchor tables and optionally full recs\n",
        "    save_anchor_tables_and_csvs(anchor, recs_anchor_gpu, recs_anchor_cpu, save_prefix=f\"anchor_{anchor}_recs\")\n",
        "    if args.save_all:\n",
        "        print(\"\\nSaving full recommendation CSVs (CPU & GPU). This may be large.\")\n",
        "        # CPU\n",
        "        rows = []\n",
        "        for i in range(len(topk_idx_cpu)):\n",
        "            idxs = topk_idx_cpu[i]\n",
        "            scores = topk_scores_cpu[i]\n",
        "            for r,(other,score) in enumerate(zip(idxs,scores), start=1):\n",
        "                rows.append({\n",
        "                    \"item_index\": i,\n",
        "                    \"stock_code_item\": item_meta[i][\"stock_code\"],\n",
        "                    \"item_description\": item_meta[i][\"description\"],\n",
        "                    \"rank\": r,\n",
        "                    \"other_index\": int(other),\n",
        "                    \"other_stock_code\": item_meta[int(other)][\"stock_code\"],\n",
        "                    \"other_description\": item_meta[int(other)][\"description\"],\n",
        "                    \"similarity\": float(score),\n",
        "                })\n",
        "        pd.DataFrame(rows).to_csv(\"recs_all_cpu.csv\", index=False)\n",
        "        # GPU\n",
        "        rows = []\n",
        "        for i in range(len(topk_idx_gpu)):\n",
        "            idxs = topk_idx_gpu[i]\n",
        "            scores = topk_scores_gpu[i]\n",
        "            for r,(other,score) in enumerate(zip(idxs,scores), start=1):\n",
        "                rows.append({\n",
        "                    \"item_index\": i,\n",
        "                    \"stock_code_item\": item_meta[i][\"stock_code\"],\n",
        "                    \"item_description\": item_meta[i][\"description\"],\n",
        "                    \"rank\": r,\n",
        "                    \"other_index\": int(other),\n",
        "                    \"other_stock_code\": item_meta[int(other)][\"stock_code\"],\n",
        "                    \"other_description\": item_meta[int(other)][\"description\"],\n",
        "                    \"similarity\": float(score),\n",
        "                })\n",
        "        pd.DataFrame(rows).to_csv(\"recs_all_gpu.csv\", index=False)\n",
        "        print(\"Saved recs_all_cpu.csv and recs_all_gpu.csv\")\n",
        "\n",
        "    # Summary table & plot\n",
        "    print(\"\\nSUMMARY:\")\n",
        "    df_summary = pd.DataFrame([\n",
        "        {\"engine\": \"CPU (SciPy) per-row\", \"time_sec\": round(t_cpu,3)},\n",
        "        {\"engine\": \"GPU (CuPy) transfer\", \"time_sec\": round(t_transfer,3)},\n",
        "        {\"engine\": \"GPU (CuPy) compute\", \"time_sec\": round(t_gpu_compute,3)},\n",
        "        {\"engine\": \"GPU (CuPy) total\", \"time_sec\": round(t_gpu_total,3)}\n",
        "    ])\n",
        "    speedup = (t_cpu / t_gpu_total) if (t_gpu_total > 0) else float('nan')\n",
        "    df_summary_print = df_summary.copy()\n",
        "    if not np.isnan(speedup):\n",
        "        df_summary_print.loc[len(df_summary_print)] = {\"engine\": \"CPU_time / GPU_total_speedup\", \"time_sec\": round(speedup,3)}\n",
        "    print(df_summary_print.to_string(index=False))\n",
        "\n",
        "    # Inline plot or saved plot based on flag\n",
        "    if args.inline_plot:\n",
        "        try:\n",
        "            plot_timing_inline(t_cpu, t_transfer, t_gpu_compute)\n",
        "        except Exception as e:\n",
        "            print(\"Warning: inline plot failed:\", e)\n",
        "    else:\n",
        "        try:\n",
        "            # fallback: save plot file\n",
        "            from matplotlib import pyplot as pltfile\n",
        "            gpu_total = t_transfer + t_gpu_compute\n",
        "            df_plot = pd.DataFrame([\n",
        "                {\"engine\": \"CPU (SciPy) per-row\", \"time_sec\": t_cpu},\n",
        "                {\"engine\": \"GPU (CuPy) transfer\", \"time_sec\": t_transfer},\n",
        "                {\"engine\": \"GPU (CuPy) compute\", \"time_sec\": t_gpu_compute},\n",
        "                {\"engine\": \"GPU (CuPy) total\", \"time_sec\": gpu_total}\n",
        "            ])\n",
        "            pltfile.figure(figsize=(8,4))\n",
        "            bars = pltfile.bar(df_plot[\"engine\"], df_plot[\"time_sec\"])\n",
        "            pltfile.ylabel(\"Seconds\")\n",
        "            pltfile.title(\"CPU vs GPU timing breakdown\")\n",
        "            for bar in bars:\n",
        "                h = bar.get_height()\n",
        "                pltfile.text(bar.get_x() + bar.get_width()/2, h + 0.5, f\"{h:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "            pltfile.tight_layout()\n",
        "            pltfile.savefig(\"timing_comparison.png\", dpi=150)\n",
        "            pltfile.close()\n",
        "            print(\"Saved timing comparison plot to timing_comparison.png\")\n",
        "        except Exception as e:\n",
        "            print(\"Warning: plot creation failed:\", e)\n",
        "\n",
        "    print_pipeline_explanation()\n",
        "    print(\"\\nDone.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if hasattr(sys, 'argv') and len(sys.argv) > 0 and \\\n",
        "       (sys.argv[0].endswith('ipykernel_launcher.py') or sys.argv[0].endswith('colab_kernel_launcher.py')):\n",
        "        main(argv=[])\n",
        "    else:\n",
        "        main(argv=sys.argv[1:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMvnxAdvkREV",
        "outputId": "aff169d1-a690-45d8-b578-3a17969ae568"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Load dataset and build host CSR (SciPy).\n",
            " loaded: items=3922, sessions=19960, time=2.48s\n",
            "\n",
            "STEP 2: Transfer CSR to GPU (CuPy).\n",
            " transfer time: 0.02s\n",
            "\n",
            "STEP 3: GPU compute top-K per item (batched).\n",
            "[GPU batch] anchors 0-63 processed (B=64), elapsed=0.02s\n",
            "[GPU batch] anchors 64-127 processed (B=64), elapsed=0.04s\n",
            "[GPU batch] anchors 128-191 processed (B=64), elapsed=0.05s\n",
            "[GPU batch] anchors 192-255 processed (B=64), elapsed=0.07s\n",
            "[GPU batch] anchors 256-319 processed (B=64), elapsed=0.09s\n",
            "[GPU batch] anchors 320-383 processed (B=64), elapsed=0.10s\n",
            "[GPU batch] anchors 384-447 processed (B=64), elapsed=0.12s\n",
            "[GPU batch] anchors 448-511 processed (B=64), elapsed=0.14s\n",
            "[GPU batch] anchors 512-575 processed (B=64), elapsed=0.15s\n",
            "[GPU batch] anchors 576-639 processed (B=64), elapsed=0.17s\n",
            "[GPU batch] anchors 640-703 processed (B=64), elapsed=0.19s\n",
            "[GPU batch] anchors 704-767 processed (B=64), elapsed=0.21s\n",
            "[GPU batch] anchors 768-831 processed (B=64), elapsed=0.23s\n",
            "[GPU batch] anchors 832-895 processed (B=64), elapsed=0.24s\n",
            "[GPU batch] anchors 896-959 processed (B=64), elapsed=0.26s\n",
            "[GPU batch] anchors 960-1023 processed (B=64), elapsed=0.27s\n",
            "[GPU batch] anchors 1024-1087 processed (B=64), elapsed=0.29s\n",
            "[GPU batch] anchors 1088-1151 processed (B=64), elapsed=0.30s\n",
            "[GPU batch] anchors 1152-1215 processed (B=64), elapsed=0.32s\n",
            "[GPU batch] anchors 1216-1279 processed (B=64), elapsed=0.33s\n",
            "[GPU batch] anchors 1280-1343 processed (B=64), elapsed=0.35s\n",
            "[GPU batch] anchors 1344-1407 processed (B=64), elapsed=0.36s\n",
            "[GPU batch] anchors 1408-1471 processed (B=64), elapsed=0.38s\n",
            "[GPU batch] anchors 1472-1535 processed (B=64), elapsed=0.39s\n",
            "[GPU batch] anchors 1536-1599 processed (B=64), elapsed=0.41s\n",
            "[GPU batch] anchors 1600-1663 processed (B=64), elapsed=0.42s\n",
            "[GPU batch] anchors 1664-1727 processed (B=64), elapsed=0.43s\n",
            "[GPU batch] anchors 1728-1791 processed (B=64), elapsed=0.45s\n",
            "[GPU batch] anchors 1792-1855 processed (B=64), elapsed=0.46s\n",
            "[GPU batch] anchors 1856-1919 processed (B=64), elapsed=0.47s\n",
            "[GPU batch] anchors 1920-1983 processed (B=64), elapsed=0.49s\n",
            "[GPU batch] anchors 1984-2047 processed (B=64), elapsed=0.50s\n",
            "[GPU batch] anchors 2048-2111 processed (B=64), elapsed=0.52s\n",
            "[GPU batch] anchors 2112-2175 processed (B=64), elapsed=0.53s\n",
            "[GPU batch] anchors 2176-2239 processed (B=64), elapsed=0.54s\n",
            "[GPU batch] anchors 2240-2303 processed (B=64), elapsed=0.56s\n",
            "[GPU batch] anchors 2304-2367 processed (B=64), elapsed=0.57s\n",
            "[GPU batch] anchors 2368-2431 processed (B=64), elapsed=0.58s\n",
            "[GPU batch] anchors 2432-2495 processed (B=64), elapsed=0.59s\n",
            "[GPU batch] anchors 2496-2559 processed (B=64), elapsed=0.60s\n",
            "[GPU batch] anchors 2560-2623 processed (B=64), elapsed=0.62s\n",
            "[GPU batch] anchors 2624-2687 processed (B=64), elapsed=0.63s\n",
            "[GPU batch] anchors 2688-2751 processed (B=64), elapsed=0.64s\n",
            "[GPU batch] anchors 2752-2815 processed (B=64), elapsed=0.66s\n",
            "[GPU batch] anchors 2816-2879 processed (B=64), elapsed=0.67s\n",
            "[GPU batch] anchors 2880-2943 processed (B=64), elapsed=0.68s\n",
            "[GPU batch] anchors 2944-3007 processed (B=64), elapsed=0.69s\n",
            "[GPU batch] anchors 3008-3071 processed (B=64), elapsed=0.70s\n",
            "[GPU batch] anchors 3072-3135 processed (B=64), elapsed=0.71s\n",
            "[GPU batch] anchors 3136-3199 processed (B=64), elapsed=0.72s\n",
            "[GPU batch] anchors 3200-3263 processed (B=64), elapsed=0.73s\n",
            "[GPU batch] anchors 3264-3327 processed (B=64), elapsed=0.74s\n",
            "[GPU batch] anchors 3328-3391 processed (B=64), elapsed=0.75s\n",
            "[GPU batch] anchors 3392-3455 processed (B=64), elapsed=0.77s\n",
            "[GPU batch] anchors 3456-3519 processed (B=64), elapsed=0.78s\n",
            "[GPU batch] anchors 3520-3583 processed (B=64), elapsed=0.79s\n",
            "[GPU batch] anchors 3584-3647 processed (B=64), elapsed=0.80s\n",
            "[GPU batch] anchors 3648-3711 processed (B=64), elapsed=0.81s\n",
            "[GPU batch] anchors 3712-3775 processed (B=64), elapsed=0.82s\n",
            "[GPU batch] anchors 3776-3839 processed (B=64), elapsed=0.83s\n",
            "[GPU batch] anchors 3840-3903 processed (B=64), elapsed=0.84s\n",
            "[GPU batch] anchors 3904-3921 processed (B=18), elapsed=0.85s\n",
            " GPU total (transfer+compute): 0.87s (compute only: 0.85s)\n",
            "\n",
            "STEP 4: CPU baseline top-K per item (for comparison).\n",
            "[CPU] completed 500/3922 items, elapsed=2.40s\n",
            "[CPU] completed 1000/3922 items, elapsed=4.74s\n",
            "[CPU] completed 1500/3922 items, elapsed=7.06s\n",
            "[CPU] completed 2000/3922 items, elapsed=9.33s\n",
            "[CPU] completed 2500/3922 items, elapsed=11.89s\n",
            "[CPU] completed 3000/3922 items, elapsed=14.17s\n",
            "[CPU] completed 3500/3922 items, elapsed=16.46s\n",
            "[CPU] completed 3922/3922 items, elapsed=18.41s\n",
            " CPU total compute: 18.41s\n",
            "\n",
            "Anchor item index = 0; stock_code = 85123A; description = WHITE HANGING HEART T-LIGHT HOLDER; sessions_with_anchor = 2198\n",
            "\n",
            "Top-K (GPU-derived):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "Top-K (CPU-derived):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "\n",
            "=== Recommendation examples for 2 products (indexes): [np.int64(0), np.int64(138)] ===\n",
            "\n",
            "Example Anchor 0 (stock_code = 85123A, description = WHITE HANGING HEART T-LIGHT HOLDER, sessions = 2198)\n",
            "\n",
            "GPU-derived top-5:\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "CPU-derived top-5:\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "Example Anchor 138 (stock_code = 85099B, description = JUMBO BAG RED RETROSPOT, sessions = 2089)\n",
            "\n",
            "GPU-derived top-5:\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "\n",
            "CPU-derived top-5:\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "Saved anchor tables: anchor_0_recs_gpu.csv, anchor_0_recs_cpu.csv\n",
            "\n",
            "SUMMARY:\n",
            "                      engine  time_sec\n",
            "         CPU (SciPy) per-row    18.406\n",
            "         GPU (CuPy) transfer     0.019\n",
            "          GPU (CuPy) compute     0.849\n",
            "            GPU (CuPy) total     0.868\n",
            "CPU_time / GPU_total_speedup    21.210\n",
            "Saved timing comparison plot to timing_comparison.png\n",
            "\n",
            "=== GPU pipeline explanation & summary ===\n",
            "1) Data ingestion & preprocessing (host): CSV -> pandas -> SciPy CSR.\n",
            "2) Transfer to GPU: SciPy CSR -> CuPy CSR (single conversion).\n",
            "3) Batched GPU compute:\n",
            "   - For each batch: compute BxN cooccurrence, normalize (device), top-k (device), transfer BxK back.\n",
            "4) CPU baseline: per-row sparse matmul + numpy top-k (highly optimized on CPU).\n",
            "\n",
            "Why GPU can be slower than CPU sometimes: kernel-launch & allocation overhead for many tiny tasks.\n",
            "Tune batch_size (e.g., 32/64/128) to amortize overhead; larger B uses more GPU memory but fewer launches.\n",
            "==========================================\n",
            "\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse, time, os, math, sys\n",
        "from typing import Dict, List, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cupy as cp\n",
        "import cupyx.scipy.sparse as cpx_sparse\n",
        "\n",
        "def parse_transaction_data(file_path: str, region: str = None):\n",
        "    \"\"\"Parse retail transaction data from CSV file\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
        "\n",
        "    transactions_df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
        "    mandatory_fields = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Quantity\", \"UnitPrice\"]\n",
        "    for field in mandatory_fields:\n",
        "        if field not in transactions_df.columns:\n",
        "            raise RuntimeError(f\"Missing mandatory field '{field}' in dataset\")\n",
        "\n",
        "    # Data cleaning and filtering pipeline\n",
        "    transactions_df = transactions_df.dropna(subset=mandatory_fields)\n",
        "    transactions_df = transactions_df[~transactions_df[\"InvoiceNo\"].astype(str).str.startswith(\"C\")]\n",
        "    transactions_df = transactions_df[transactions_df[\"Quantity\"] > 0]\n",
        "    transactions_df = transactions_df[transactions_df[\"UnitPrice\"] > 0.0]\n",
        "    if region and \"Country\" in transactions_df.columns:\n",
        "        transactions_df = transactions_df[transactions_df[\"Country\"] == region]\n",
        "\n",
        "    # Product encoding\n",
        "    transactions_df[\"StockCode\"] = transactions_df[\"StockCode\"].astype(str)\n",
        "    distinct_products = pd.Series(transactions_df[\"StockCode\"].unique())\n",
        "    product_mapping = {prod: position for position, prod in enumerate(distinct_products)}\n",
        "    transactions_df[\"product_id\"] = transactions_df[\"StockCode\"].map(product_mapping)\n",
        "\n",
        "    # Invoice/session encoding\n",
        "    transactions_df[\"InvoiceNo\"] = transactions_df[\"InvoiceNo\"].astype(str)\n",
        "    distinct_invoices = pd.Series(transactions_df[\"InvoiceNo\"].unique())\n",
        "    invoice_mapping = {invoice: position for position, invoice in enumerate(distinct_invoices)}\n",
        "    transactions_df[\"basket_id\"] = transactions_df[\"InvoiceNo\"].map(invoice_mapping)\n",
        "\n",
        "    # Remove duplicate product-basket pairs\n",
        "    unique_pairs = transactions_df.drop_duplicates(subset=[\"basket_id\", \"product_id\"])\n",
        "\n",
        "    # Build sparse matrix representation\n",
        "    row_indices = unique_pairs[\"product_id\"].to_numpy(dtype=np.int32)\n",
        "    col_indices = unique_pairs[\"basket_id\"].to_numpy(dtype=np.int32)\n",
        "    values = (np.ones_like(row_indices, dtype=np.int8)).astype(np.int8)\n",
        "\n",
        "    total_products = len(distinct_products)\n",
        "    total_baskets = len(distinct_invoices)\n",
        "\n",
        "    product_basket_matrix = sparse.csr_matrix((values, (row_indices, col_indices)),\n",
        "                                              shape=(total_products, total_baskets),\n",
        "                                              dtype=np.int32)\n",
        "\n",
        "    # Extract product metadata\n",
        "    product_metadata: Dict[int, Dict] = {}\n",
        "    for product_idx, group_data in transactions_df.groupby(\"product_id\"):\n",
        "        desc_value = group_data[\"Description\"].mode().iloc[0] if \"Description\" in group_data else \"\"\n",
        "        product_metadata[int(product_idx)] = {\n",
        "            \"stock_code\": group_data[\"StockCode\"].iloc[0],\n",
        "            \"description\": str(desc_value)\n",
        "        }\n",
        "\n",
        "    return product_basket_matrix, product_metadata, total_baskets\n",
        "\n",
        "def convert_scipy_to_cupy_sparse(scipy_matrix: sparse.csr_matrix):\n",
        "    \"\"\"Transfer sparse matrix from CPU (SciPy) to GPU (CuPy)\"\"\"\n",
        "    coo_format = scipy_matrix.tocoo()\n",
        "    gpu_data = cp.asarray(coo_format.data, dtype=cp.float32)\n",
        "    gpu_rows = cp.asarray(coo_format.row)\n",
        "    gpu_cols = cp.asarray(coo_format.col)\n",
        "    gpu_coo_matrix = cpx_sparse.coo_matrix((gpu_data, (gpu_rows, gpu_cols)), shape=scipy_matrix.shape)\n",
        "    return gpu_coo_matrix.tocsr()\n",
        "\n",
        "\n",
        "def compute_similarities_gpu_batched(product_matrix_gpu, top_k: int, batch_count: int = 64):\n",
        "    \"\"\"Compute top-K similar products using GPU acceleration with batching\"\"\"\n",
        "    total_products = int(product_matrix_gpu.shape[0])\n",
        "\n",
        "    # Calculate product frequency (diagonal elements)\n",
        "    diagonal_values_gpu = product_matrix_gpu.multiply(product_matrix_gpu).sum(axis=1).ravel().astype(cp.int32)\n",
        "    diagonal_values_cpu = cp.asnumpy(diagonal_values_gpu)\n",
        "\n",
        "    top_indices_collection = [None] * total_products\n",
        "    top_scores_collection = [None] * total_products\n",
        "\n",
        "    computation_start = time.time()\n",
        "    sqrt_diagonal_gpu = cp.sqrt(cp.maximum(diagonal_values_gpu.astype(cp.float32), 1.0))\n",
        "    product_indices = np.arange(total_products, dtype=np.int32)\n",
        "\n",
        "    for batch_start in range(0, total_products, batch_count):\n",
        "        batch_end = min(batch_start + batch_count, total_products)\n",
        "        current_batch = product_indices[batch_start:batch_end]\n",
        "        batch_length = len(current_batch)\n",
        "\n",
        "        # Extract batch rows and compute cooccurrence matrix\n",
        "        batch_matrix = product_matrix_gpu[current_batch, :]\n",
        "        cooccurrence_batch = batch_matrix.dot(product_matrix_gpu.T)\n",
        "        cooccurrence_dense = cooccurrence_batch.toarray().astype(cp.float32)\n",
        "\n",
        "        denominator_matrix = sqrt_diagonal_gpu[cp.asarray(current_batch, dtype=cp.int32)].astype(cp.float32)[:, None] * sqrt_diagonal_gpu[None, :]\n",
        "\n",
        "        similarity_batch = cp.where(denominator_matrix > 0.0,\n",
        "                                    cooccurrence_dense / denominator_matrix,\n",
        "                                    0.0).astype(cp.float32)\n",
        "\n",
        "        # Zero out self-similarities\n",
        "        similarity_batch[cp.arange(batch_length, dtype=cp.int32),\n",
        "                        cp.asarray(current_batch, dtype=cp.int32)] = 0.0\n",
        "\n",
        "        # Extract top-K per row\n",
        "        if top_k >= total_products:\n",
        "            top_k_indices = cp.argsort(-similarity_batch, axis=1)[:, :top_k]\n",
        "            top_k_scores = cp.take_along_axis(similarity_batch, top_k_indices, axis=1)\n",
        "        else:\n",
        "            partition_indices = cp.argpartition(-similarity_batch, top_k, axis=1)[:, :top_k]\n",
        "            partition_scores = cp.take_along_axis(similarity_batch, partition_indices, axis=1)\n",
        "            sort_order = cp.argsort(-partition_scores, axis=1)\n",
        "            top_k_indices = cp.take_along_axis(partition_indices, sort_order, axis=1)\n",
        "            top_k_scores = cp.take_along_axis(partition_scores, sort_order, axis=1)\n",
        "\n",
        "        # Transfer results to CPU\n",
        "        top_k_indices_cpu = cp.asnumpy(top_k_indices.astype(cp.int32))\n",
        "        top_k_scores_cpu = cp.asnumpy(top_k_scores.astype(cp.float32))\n",
        "\n",
        "        for local_index in range(batch_length):\n",
        "            global_product = int(current_batch[local_index])\n",
        "            top_indices_collection[global_product] = top_k_indices_cpu[local_index].astype(np.int32)\n",
        "            top_scores_collection[global_product] = top_k_scores_cpu[local_index].astype(np.float32)\n",
        "\n",
        "        elapsed_time = time.time() - computation_start\n",
        "        print(f\"[GPU processing] batch {batch_start}-{batch_end-1} complete (size={batch_length}), time={elapsed_time:.2f}s\")\n",
        "\n",
        "    total_gpu_time = time.time() - computation_start\n",
        "    return top_indices_collection, top_scores_collection, diagonal_values_cpu, total_gpu_time\n",
        "\n",
        "def compute_similarities_cpu_baseline(product_matrix_scipy, top_k: int):\n",
        "    \"\"\"Baseline CPU implementation for similarity computation\"\"\"\n",
        "    total_products = product_matrix_scipy.shape[0]\n",
        "    diagonal_values = product_matrix_scipy.multiply(product_matrix_scipy).sum(axis=1).A1.astype(np.int32)\n",
        "    top_indices_collection = [None] * total_products\n",
        "    top_scores_collection = [None] * total_products\n",
        "\n",
        "    computation_start = time.time()\n",
        "    for product_id in range(total_products):\n",
        "        product_vector = product_matrix_scipy.getrow(product_id)\n",
        "        cooccurrence_vector = product_vector.dot(product_matrix_scipy.T)\n",
        "        cooccurrence_array = cooccurrence_vector.toarray().ravel().astype(np.float32)\n",
        "\n",
        "        denominator = math.sqrt(diagonal_values[product_id]) * np.sqrt(np.maximum(diagonal_values, 1.0))\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            similarity_vector = np.where(denominator > 0,\n",
        "                                        cooccurrence_array / denominator,\n",
        "                                        0.0).astype(np.float32)\n",
        "        similarity_vector[product_id] = 0.0\n",
        "\n",
        "        if top_k >= similarity_vector.size:\n",
        "            sorted_indices = np.argsort(-similarity_vector)[:top_k]\n",
        "        else:\n",
        "            partition = np.argpartition(-similarity_vector, top_k)[:top_k]\n",
        "            sorted_indices = partition[np.argsort(-similarity_vector[partition])]\n",
        "\n",
        "        top_indices_collection[product_id] = sorted_indices.astype(np.int32)\n",
        "        top_scores_collection[product_id] = similarity_vector[sorted_indices].astype(np.float32)\n",
        "\n",
        "        if (product_id + 1) % 500 == 0 or (product_id + 1) == total_products:\n",
        "            elapsed_time = time.time() - computation_start\n",
        "            print(f\"[CPU processing] {product_id+1}/{total_products} products done, time={elapsed_time:.2f}s\")\n",
        "\n",
        "    total_cpu_time = time.time() - computation_start\n",
        "    return top_indices_collection, top_scores_collection, diagonal_values, total_cpu_time\n",
        "\n",
        "\n",
        "def generate_recommendation_report(reference_product: int, top_indices_list: List[np.ndarray],\n",
        "                                  top_scores_list: List[np.ndarray],\n",
        "                                  product_matrix_scipy: sparse.csr_matrix,\n",
        "                                  diagonal_values: np.ndarray,\n",
        "                                  product_metadata: Dict[int, Dict],\n",
        "                                  total_baskets: int) -> pd.DataFrame:\n",
        "    \"\"\"Generate detailed recommendation report for a reference product\"\"\"\n",
        "    cooccurrence_vector = product_matrix_scipy.getrow(reference_product).dot(product_matrix_scipy.T)\n",
        "    cooccurrence_array = cooccurrence_vector.toarray().ravel().astype(np.int32)\n",
        "    denominator = math.sqrt(diagonal_values[reference_product]) * np.sqrt(np.maximum(diagonal_values, 1.0))\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        similarity_exact = np.where(denominator > 0.0,\n",
        "                                    cooccurrence_array.astype(np.float32) / denominator,\n",
        "                                    0.0).astype(np.float32)\n",
        "    similarity_exact[reference_product] = 0.0\n",
        "\n",
        "    recommended_indices = top_indices_list[reference_product]\n",
        "    report_rows = []\n",
        "    for position, related_product in enumerate(recommended_indices, start=1):\n",
        "        cooccurrence_count = int(cooccurrence_array[int(related_product)])\n",
        "        similarity_score = float(similarity_exact[int(related_product)])\n",
        "        lift_value = 0.0\n",
        "        if diagonal_values[reference_product] > 0 and diagonal_values[int(related_product)] > 0:\n",
        "            prob_both = cooccurrence_count / float(total_baskets)\n",
        "            prob_reference = diagonal_values[reference_product] / float(total_baskets)\n",
        "            prob_related = diagonal_values[int(related_product)] / float(total_baskets)\n",
        "            lift_value = prob_both / (prob_reference * prob_related) if (prob_reference * prob_related) > 0 else 0.0\n",
        "        report_rows.append({\n",
        "            \"rank\": position,\n",
        "            \"item_index\": int(related_product),\n",
        "            \"stock_code\": product_metadata[int(related_product)][\"stock_code\"] if int(related_product) in product_metadata else \"\",\n",
        "            \"description\": product_metadata[int(related_product)][\"description\"] if int(related_product) in product_metadata else \"\",\n",
        "            \"cooccurrence\": cooccurrence_count,\n",
        "            \"similarity\": similarity_score,\n",
        "            \"lift\": lift_value,\n",
        "            \"sessions_with_other\": int(diagonal_values[int(related_product)])\n",
        "        })\n",
        "    return pd.DataFrame(report_rows)\n",
        "\n",
        "\n",
        "def visualize_performance_comparison(cpu_duration, gpu_transfer_time, gpu_compute_time):\n",
        "    \"\"\"Create visualization comparing CPU and GPU performance\"\"\"\n",
        "    gpu_combined = gpu_transfer_time + gpu_compute_time\n",
        "    category_labels = [\"CPU (SciPy) computation\", \"GPU data transfer\", \"GPU computation\", \"GPU combined\"]\n",
        "    duration_values = [cpu_duration, gpu_transfer_time, gpu_compute_time, gpu_combined]\n",
        "    plt.figure(figsize=(8,4))\n",
        "    bar_chart = plt.bar(category_labels, duration_values)\n",
        "    plt.ylabel(\"Execution Time (seconds)\")\n",
        "    plt.title(\"Performance Analysis: CPU vs GPU\")\n",
        "    for bar in bar_chart:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.3,\n",
        "                f\"{height:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def export_recommendation_tables(reference_product, gpu_recommendations, cpu_recommendations, output_prefix=\"product_recs\"):\n",
        "    \"\"\"Save recommendation tables to CSV files\"\"\"\n",
        "    gpu_output = f\"{output_prefix}_gpu.csv\"\n",
        "    cpu_output = f\"{output_prefix}_cpu.csv\"\n",
        "    gpu_recommendations.to_csv(gpu_output, index=False)\n",
        "    cpu_recommendations.to_csv(cpu_output, index=False)\n",
        "    print(f\"Exported recommendation tables: {gpu_output}, {cpu_output}\")\n",
        "\n",
        "def display_implementation_summary():\n",
        "    \"\"\"Display technical summary of the recommendation pipeline\"\"\"\n",
        "    print(\"\\n=== Implementation Architecture Overview ===\")\n",
        "    print(\"Step 1: Data preprocessing on host - CSV parsing into SciPy sparse matrix format.\")\n",
        "    print(\"Step 2: Data migration to GPU - Convert SciPy CSR to CuPy CSR (single transfer).\")\n",
        "    print(\"Step 3: GPU batch processing:\")\n",
        "    print(\"   - Process batches: calculate BxN cooccurrence, normalize on device, extract top-k, transfer results.\")\n",
        "    print(\"Step 4: CPU reference implementation: row-wise sparse operations with NumPy top-k selection.\")\n",
        "    print(\"\\nPerformance considerations: GPU overhead from kernel launches may exceed benefits for small workloads.\")\n",
        "    print(\"Optimization strategy: Increase batch_size parameter (32/64/128) to reduce overhead; larger batches require more VRAM.\")\n",
        "    print(\"============================================\\n\")\n",
        "\n",
        "def main(argv=None):\n",
        "    argument_parser = argparse.ArgumentParser()\n",
        "    argument_parser.add_argument(\"--csv\", type=str, default=\"OnlineRetail_cached.csv\", help=\"Input CSV file path\")\n",
        "    argument_parser.add_argument(\"--k\", type=int, default=10, help=\"Number of top recommendations\")\n",
        "    argument_parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size for GPU processing\")\n",
        "    argument_parser.add_argument(\"--anchor_by\", choices=[\"most_popular\",\"random\",\"id\"], default=\"most_popular\")\n",
        "    argument_parser.add_argument(\"--anchor_id\", type=int, default=None)\n",
        "    argument_parser.add_argument(\"--country\", type=str, default=None)\n",
        "    argument_parser.add_argument(\"--save_all\", action=\"store_true\", help=\"Export complete recommendation datasets\")\n",
        "    argument_parser.add_argument(\"--inline_plot\", action=\"store_true\", help=\"Display performance visualization inline\")\n",
        "    config = argument_parser.parse_args(argv)\n",
        "\n",
        "    input_file = config.csv\n",
        "    recommendations_count = config.k\n",
        "    processing_batch_size = config.batch_size\n",
        "\n",
        "    print(\"Phase 1: Loading and preprocessing transaction dataset.\")\n",
        "    start_timestamp = time.time()\n",
        "    product_basket_matrix_cpu, product_metadata, total_baskets = parse_transaction_data(input_file, region=config.country)\n",
        "    end_timestamp = time.time()\n",
        "    print(f\" Dataset loaded: products={product_basket_matrix_cpu.shape[0]}, baskets={product_basket_matrix_cpu.shape[1]}, duration={end_timestamp-start_timestamp:.2f}s\")\n",
        "\n",
        "    print(\"\\nPhase 2: Transferring sparse matrix to GPU memory.\")\n",
        "    start_timestamp = time.time()\n",
        "    product_basket_matrix_gpu = convert_scipy_to_cupy_sparse(product_basket_matrix_cpu)\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    transfer_duration = time.time() - start_timestamp\n",
        "    print(f\" Transfer completed: {transfer_duration:.2f}s\")\n",
        "\n",
        "    print(\"\\nPhase 3: Computing recommendations using GPU (batched processing).\")\n",
        "    start_timestamp = time.time()\n",
        "    gpu_top_indices, gpu_top_scores, gpu_diagonal, gpu_compute_duration = compute_similarities_gpu_batched(\n",
        "        product_basket_matrix_gpu, top_k=recommendations_count, batch_count=processing_batch_size)\n",
        "    gpu_total_duration = transfer_duration + gpu_compute_duration\n",
        "    print(f\" GPU execution (transfer+compute): {gpu_total_duration:.2f}s (compute only: {gpu_compute_duration:.2f}s)\")\n",
        "\n",
        "    print(\"\\nPhase 4: Computing recommendations using CPU (baseline reference).\")\n",
        "    cpu_top_indices, cpu_top_scores, cpu_diagonal, cpu_duration = compute_similarities_cpu_baseline(\n",
        "        product_basket_matrix_cpu, top_k=recommendations_count)\n",
        "    print(f\" CPU execution duration: {cpu_duration:.2f}s\")\n",
        "\n",
        "    # Select reference product for demonstration\n",
        "    if config.anchor_by == \"most_popular\":\n",
        "        reference_product = int(np.argmax(cpu_diagonal))\n",
        "    elif config.anchor_by == \"random\":\n",
        "        reference_product = int(np.random.default_rng(1).integers(0, product_basket_matrix_cpu.shape[0]))\n",
        "    else:\n",
        "        if config.anchor_id is None:\n",
        "            raise ValueError(\"Must specify anchor_id when using anchor_by='id'\")\n",
        "        reference_product = config.anchor_id\n",
        "\n",
        "    reference_stock_code = product_metadata[reference_product]['stock_code']\n",
        "    reference_description = product_metadata[reference_product]['description']\n",
        "\n",
        "    print(f\"\\nReference product: index={reference_product}; \"\n",
        "          f\"stock_code={reference_stock_code}; \"\n",
        "          f\"description={reference_description}; \"\n",
        "          f\"basket_occurrences={int(cpu_diagonal[reference_product])}\")\n",
        "\n",
        "    # Generate recommendation reports\n",
        "    gpu_recommendations = generate_recommendation_report(reference_product, gpu_top_indices, gpu_top_scores,\n",
        "                                                        product_basket_matrix_cpu, gpu_diagonal,\n",
        "                                                        product_metadata, total_baskets)\n",
        "    cpu_recommendations = generate_recommendation_report(reference_product, cpu_top_indices, cpu_top_scores,\n",
        "                                                        product_basket_matrix_cpu, cpu_diagonal,\n",
        "                                                        product_metadata, total_baskets)\n",
        "\n",
        "    print(\"\\nRecommendations (GPU-generated):\")\n",
        "    print(gpu_recommendations.to_string(index=False))\n",
        "\n",
        "    print(\"\\nRecommendations (CPU-generated):\")\n",
        "    print(cpu_recommendations.to_string(index=False))\n",
        "\n",
        "    # Display sample recommendations for top products\n",
        "    try:\n",
        "        top_two_products = list(np.argsort(-cpu_diagonal)[:2])\n",
        "        print(f\"\\n\\n=== Sample recommendations for top 2 products (indices): {top_two_products} ===\")\n",
        "        for sample_product in top_two_products:\n",
        "            sample_stock = product_metadata[sample_product]['stock_code']\n",
        "            sample_desc = product_metadata[sample_product]['description']\n",
        "            print(f\"\\nSample Product {sample_product} (stock_code={sample_stock}, description={sample_desc}, baskets={int(cpu_diagonal[sample_product])})\")\n",
        "            sample_gpu_recs = generate_recommendation_report(sample_product, gpu_top_indices, gpu_top_scores,\n",
        "                                                            product_basket_matrix_cpu, gpu_diagonal,\n",
        "                                                            product_metadata, total_baskets)\n",
        "            sample_cpu_recs = generate_recommendation_report(sample_product, cpu_top_indices, cpu_top_scores,\n",
        "                                                            product_basket_matrix_cpu, cpu_diagonal,\n",
        "                                                            product_metadata, total_baskets)\n",
        "            print(\"\\nGPU recommendations (top 5):\")\n",
        "            print(sample_gpu_recs.head(5).to_string(index=False))\n",
        "            print(\"\\nCPU recommendations (top 5):\")\n",
        "            print(sample_cpu_recs.head(5).to_string(index=False))\n",
        "    except Exception as error:\n",
        "        print(\"Unable to generate sample recommendations:\", error)\n",
        "\n",
        "    # Export results\n",
        "    export_recommendation_tables(reference_product, gpu_recommendations, cpu_recommendations,\n",
        "                                output_prefix=f\"product_{reference_product}_recommendations\")\n",
        "    if config.save_all:\n",
        "        print(\"\\nExporting complete recommendation datasets. This may take time for large catalogs.\")\n",
        "        # CPU results export\n",
        "        all_cpu_rows = []\n",
        "        for prod_idx in range(len(cpu_top_indices)):\n",
        "            indices = cpu_top_indices[prod_idx]\n",
        "            scores = cpu_top_scores[prod_idx]\n",
        "            for rank_pos, (related_idx, score_val) in enumerate(zip(indices, scores), start=1):\n",
        "                all_cpu_rows.append({\n",
        "                    \"item_index\": prod_idx,\n",
        "                    \"stock_code_item\": product_metadata[prod_idx][\"stock_code\"],\n",
        "                    \"item_description\": product_metadata[prod_idx][\"description\"],\n",
        "                    \"rank\": rank_pos,\n",
        "                    \"other_index\": int(related_idx),\n",
        "                    \"other_stock_code\": product_metadata[int(related_idx)][\"stock_code\"],\n",
        "                    \"other_description\": product_metadata[int(related_idx)][\"description\"],\n",
        "                    \"similarity\": float(score_val),\n",
        "                })\n",
        "        pd.DataFrame(all_cpu_rows).to_csv(\"recommendations_complete_cpu.csv\", index=False)\n",
        "        # GPU results export\n",
        "        all_gpu_rows = []\n",
        "        for prod_idx in range(len(gpu_top_indices)):\n",
        "            indices = gpu_top_indices[prod_idx]\n",
        "            scores = gpu_top_scores[prod_idx]\n",
        "            for rank_pos, (related_idx, score_val) in enumerate(zip(indices, scores), start=1):\n",
        "                all_gpu_rows.append({\n",
        "                    \"item_index\": prod_idx,\n",
        "                    \"stock_code_item\": product_metadata[prod_idx][\"stock_code\"],\n",
        "                    \"item_description\": product_metadata[prod_idx][\"description\"],\n",
        "                    \"rank\": rank_pos,\n",
        "                    \"other_index\": int(related_idx),\n",
        "                    \"other_stock_code\": product_metadata[int(related_idx)][\"stock_code\"],\n",
        "                    \"other_description\": product_metadata[int(related_idx)][\"description\"],\n",
        "                    \"similarity\": float(score_val),\n",
        "                })\n",
        "        pd.DataFrame(all_gpu_rows).to_csv(\"recommendations_complete_gpu.csv\", index=False)\n",
        "        print(\"Exported recommendations_complete_cpu.csv and recommendations_complete_gpu.csv\")\n",
        "\n",
        "    # Performance summary\n",
        "    print(\"\\nPERFORMANCE SUMMARY:\")\n",
        "    summary_data = pd.DataFrame([\n",
        "        {\"computation_method\": \"CPU (SciPy) row-wise\", \"execution_time_sec\": round(cpu_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) data transfer\", \"execution_time_sec\": round(transfer_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) computation\", \"execution_time_sec\": round(gpu_compute_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) combined\", \"execution_time_sec\": round(gpu_total_duration, 3)}\n",
        "    ])\n",
        "    speedup_factor = (cpu_duration / gpu_total_duration) if (gpu_total_duration > 0) else float('nan')\n",
        "    summary_display = summary_data.copy()\n",
        "    if not np.isnan(speedup_factor):\n",
        "        summary_display.loc[len(summary_display)] = {\n",
        "            \"computation_method\": \"Speedup (CPU/GPU)\",\n",
        "            \"execution_time_sec\": round(speedup_factor, 3)\n",
        "        }\n",
        "    print(summary_display.to_string(index=False))\n",
        "\n",
        "    # Visualization\n",
        "    if config.inline_plot:\n",
        "        try:\n",
        "            visualize_performance_comparison(cpu_duration, transfer_duration, gpu_compute_duration)\n",
        "        except Exception as error:\n",
        "            print(\"Warning: inline visualization failed:\", error)\n",
        "    else:\n",
        "        try:\n",
        "            from matplotlib import pyplot as plot_module\n",
        "            gpu_combined = transfer_duration + gpu_compute_duration\n",
        "            plot_data = pd.DataFrame([\n",
        "                {\"computation_method\": \"CPU (SciPy) row-wise\", \"execution_time_sec\": cpu_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) data transfer\", \"execution_time_sec\": transfer_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) computation\", \"execution_time_sec\": gpu_compute_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) combined\", \"execution_time_sec\": gpu_combined}\n",
        "            ])\n",
        "            plot_module.figure(figsize=(8, 4))\n",
        "            bar_plot = plot_module.bar(plot_data[\"computation_method\"], plot_data[\"execution_time_sec\"])\n",
        "            plot_module.ylabel(\"Execution Time (seconds)\")\n",
        "            plot_module.title(\"Performance Comparison: CPU vs GPU\")\n",
        "            for bar in bar_plot:\n",
        "                height = bar.get_height()\n",
        "                plot_module.text(bar.get_x() + bar.get_width()/2, height + 0.5,\n",
        "                               f\"{height:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "            plot_module.tight_layout()\n",
        "            plot_module.savefig(\"performance_analysis.png\", dpi=150)\n",
        "            plot_module.close()\n",
        "            print(\"Performance visualization saved: performance_analysis.png\")\n",
        "        except Exception as error:\n",
        "            print(\"Warning: visualization generation failed:\", error)\n",
        "\n",
        "    display_implementation_summary()\n",
        "    print(\"\\nExecution completed successfully.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if hasattr(sys, 'argv') and len(sys.argv) > 0 and \\\n",
        "       (sys.argv[0].endswith('ipykernel_launcher.py') or sys.argv[0].endswith('colab_kernel_launcher.py')):\n",
        "        main(argv=[])\n",
        "    else:\n",
        "        main(argv=sys.argv[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYxT8Gm_tZan",
        "outputId": "46e4143c-0804-42fd-ff2f-669789c4a1e0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Loading and preprocessing transaction dataset.\n",
            " Dataset loaded: products=3922, baskets=19960, duration=2.73s\n",
            "\n",
            "Phase 2: Transferring sparse matrix to GPU memory.\n",
            " Transfer completed: 0.02s\n",
            "\n",
            "Phase 3: Computing recommendations using GPU (batched processing).\n",
            "[GPU processing] batch 0-63 complete (size=64), time=0.02s\n",
            "[GPU processing] batch 64-127 complete (size=64), time=0.03s\n",
            "[GPU processing] batch 128-191 complete (size=64), time=0.04s\n",
            "[GPU processing] batch 192-255 complete (size=64), time=0.06s\n",
            "[GPU processing] batch 256-319 complete (size=64), time=0.07s\n",
            "[GPU processing] batch 320-383 complete (size=64), time=0.09s\n",
            "[GPU processing] batch 384-447 complete (size=64), time=0.10s\n",
            "[GPU processing] batch 448-511 complete (size=64), time=0.11s\n",
            "[GPU processing] batch 512-575 complete (size=64), time=0.13s\n",
            "[GPU processing] batch 576-639 complete (size=64), time=0.14s\n",
            "[GPU processing] batch 640-703 complete (size=64), time=0.15s\n",
            "[GPU processing] batch 704-767 complete (size=64), time=0.17s\n",
            "[GPU processing] batch 768-831 complete (size=64), time=0.18s\n",
            "[GPU processing] batch 832-895 complete (size=64), time=0.20s\n",
            "[GPU processing] batch 896-959 complete (size=64), time=0.21s\n",
            "[GPU processing] batch 960-1023 complete (size=64), time=0.22s\n",
            "[GPU processing] batch 1024-1087 complete (size=64), time=0.24s\n",
            "[GPU processing] batch 1088-1151 complete (size=64), time=0.25s\n",
            "[GPU processing] batch 1152-1215 complete (size=64), time=0.26s\n",
            "[GPU processing] batch 1216-1279 complete (size=64), time=0.28s\n",
            "[GPU processing] batch 1280-1343 complete (size=64), time=0.29s\n",
            "[GPU processing] batch 1344-1407 complete (size=64), time=0.30s\n",
            "[GPU processing] batch 1408-1471 complete (size=64), time=0.31s\n",
            "[GPU processing] batch 1472-1535 complete (size=64), time=0.32s\n",
            "[GPU processing] batch 1536-1599 complete (size=64), time=0.33s\n",
            "[GPU processing] batch 1600-1663 complete (size=64), time=0.34s\n",
            "[GPU processing] batch 1664-1727 complete (size=64), time=0.35s\n",
            "[GPU processing] batch 1728-1791 complete (size=64), time=0.36s\n",
            "[GPU processing] batch 1792-1855 complete (size=64), time=0.37s\n",
            "[GPU processing] batch 1856-1919 complete (size=64), time=0.38s\n",
            "[GPU processing] batch 1920-1983 complete (size=64), time=0.39s\n",
            "[GPU processing] batch 1984-2047 complete (size=64), time=0.41s\n",
            "[GPU processing] batch 2048-2111 complete (size=64), time=0.42s\n",
            "[GPU processing] batch 2112-2175 complete (size=64), time=0.43s\n",
            "[GPU processing] batch 2176-2239 complete (size=64), time=0.44s\n",
            "[GPU processing] batch 2240-2303 complete (size=64), time=0.44s\n",
            "[GPU processing] batch 2304-2367 complete (size=64), time=0.45s\n",
            "[GPU processing] batch 2368-2431 complete (size=64), time=0.46s\n",
            "[GPU processing] batch 2432-2495 complete (size=64), time=0.47s\n",
            "[GPU processing] batch 2496-2559 complete (size=64), time=0.48s\n",
            "[GPU processing] batch 2560-2623 complete (size=64), time=0.49s\n",
            "[GPU processing] batch 2624-2687 complete (size=64), time=0.50s\n",
            "[GPU processing] batch 2688-2751 complete (size=64), time=0.51s\n",
            "[GPU processing] batch 2752-2815 complete (size=64), time=0.52s\n",
            "[GPU processing] batch 2816-2879 complete (size=64), time=0.52s\n",
            "[GPU processing] batch 2880-2943 complete (size=64), time=0.53s\n",
            "[GPU processing] batch 2944-3007 complete (size=64), time=0.54s\n",
            "[GPU processing] batch 3008-3071 complete (size=64), time=0.55s\n",
            "[GPU processing] batch 3072-3135 complete (size=64), time=0.56s\n",
            "[GPU processing] batch 3136-3199 complete (size=64), time=0.57s\n",
            "[GPU processing] batch 3200-3263 complete (size=64), time=0.58s\n",
            "[GPU processing] batch 3264-3327 complete (size=64), time=0.58s\n",
            "[GPU processing] batch 3328-3391 complete (size=64), time=0.59s\n",
            "[GPU processing] batch 3392-3455 complete (size=64), time=0.60s\n",
            "[GPU processing] batch 3456-3519 complete (size=64), time=0.61s\n",
            "[GPU processing] batch 3520-3583 complete (size=64), time=0.62s\n",
            "[GPU processing] batch 3584-3647 complete (size=64), time=0.63s\n",
            "[GPU processing] batch 3648-3711 complete (size=64), time=0.64s\n",
            "[GPU processing] batch 3712-3775 complete (size=64), time=0.65s\n",
            "[GPU processing] batch 3776-3839 complete (size=64), time=0.66s\n",
            "[GPU processing] batch 3840-3903 complete (size=64), time=0.67s\n",
            "[GPU processing] batch 3904-3921 complete (size=18), time=0.67s\n",
            " GPU execution (transfer+compute): 0.69s (compute only: 0.67s)\n",
            "\n",
            "Phase 4: Computing recommendations using CPU (baseline reference).\n",
            "[CPU processing] 500/3922 products done, time=2.32s\n",
            "[CPU processing] 1000/3922 products done, time=6.10s\n",
            "[CPU processing] 1500/3922 products done, time=8.81s\n",
            "[CPU processing] 2000/3922 products done, time=11.27s\n",
            "[CPU processing] 2500/3922 products done, time=13.51s\n",
            "[CPU processing] 3000/3922 products done, time=15.78s\n",
            "[CPU processing] 3500/3922 products done, time=18.05s\n",
            "[CPU processing] 3922/3922 products done, time=19.97s\n",
            " CPU execution duration: 19.97s\n",
            "\n",
            "Reference product: index=0; stock_code=85123A; description=WHITE HANGING HEART T-LIGHT HOLDER; basket_occurrences=2198\n",
            "\n",
            "Recommendations (GPU-generated):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "Recommendations (CPU-generated):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "\n",
            "=== Sample recommendations for top 2 products (indices): [np.int64(0), np.int64(138)] ===\n",
            "\n",
            "Sample Product 0 (stock_code=85123A, description=WHITE HANGING HEART T-LIGHT HOLDER, baskets=2198)\n",
            "\n",
            "GPU recommendations (top 5):\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "CPU recommendations (top 5):\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "Sample Product 138 (stock_code=85099B, description=JUMBO BAG RED RETROSPOT, baskets=2089)\n",
            "\n",
            "GPU recommendations (top 5):\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "\n",
            "CPU recommendations (top 5):\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "Exported recommendation tables: product_0_recommendations_gpu.csv, product_0_recommendations_cpu.csv\n",
            "\n",
            "PERFORMANCE SUMMARY:\n",
            "      computation_method  execution_time_sec\n",
            "    CPU (SciPy) row-wise              19.969\n",
            "GPU (CuPy) data transfer               0.019\n",
            "  GPU (CuPy) computation               0.675\n",
            "     GPU (CuPy) combined               0.693\n",
            "       Speedup (CPU/GPU)              28.797\n",
            "Performance visualization saved: performance_analysis.png\n",
            "\n",
            "=== Implementation Architecture Overview ===\n",
            "Step 1: Data preprocessing on host - CSV parsing into SciPy sparse matrix format.\n",
            "Step 2: Data migration to GPU - Convert SciPy CSR to CuPy CSR (single transfer).\n",
            "Step 3: GPU batch processing:\n",
            "   - Process batches: calculate BxN cooccurrence, normalize on device, extract top-k, transfer results.\n",
            "Step 4: CPU reference implementation: row-wise sparse operations with NumPy top-k selection.\n",
            "\n",
            "Performance considerations: GPU overhead from kernel launches may exceed benefits for small workloads.\n",
            "Optimization strategy: Increase batch_size parameter (32/64/128) to reduce overhead; larger batches require more VRAM.\n",
            "============================================\n",
            "\n",
            "\n",
            "Execution completed successfully.\n"
          ]
        }
      ]
    }
  ]
}