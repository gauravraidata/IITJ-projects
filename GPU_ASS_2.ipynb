{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdzCmzHpvBaQkZ+eYfFM11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravraidata/IITJ-projects/blob/main/GPU_ASS_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse, time, os, math, sys\n",
        "from typing import Dict, List, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cupy as cp\n",
        "import cupyx.scipy.sparse as cpx_sparse"
      ],
      "metadata": {
        "id": "-4PX1_WVwQlv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_transaction_data(file_path: str, region: str = None):\n",
        "    \"\"\"Parse retail transaction data from CSV file\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
        "\n",
        "    transactions_df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
        "    mandatory_fields = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Quantity\", \"UnitPrice\"]\n",
        "    for field in mandatory_fields:\n",
        "        if field not in transactions_df.columns:\n",
        "            raise RuntimeError(f\"Missing mandatory field '{field}' in dataset\")\n",
        "\n",
        "    # Data cleaning and filtering pipeline\n",
        "    transactions_df = transactions_df.dropna(subset=mandatory_fields)\n",
        "    transactions_df = transactions_df[~transactions_df[\"InvoiceNo\"].astype(str).str.startswith(\"C\")]\n",
        "    transactions_df = transactions_df[transactions_df[\"Quantity\"] > 0]\n",
        "    transactions_df = transactions_df[transactions_df[\"UnitPrice\"] > 0.0]\n",
        "    if region and \"Country\" in transactions_df.columns:\n",
        "        transactions_df = transactions_df[transactions_df[\"Country\"] == region]\n",
        "\n",
        "    # Product encoding\n",
        "    transactions_df[\"StockCode\"] = transactions_df[\"StockCode\"].astype(str)\n",
        "    distinct_products = pd.Series(transactions_df[\"StockCode\"].unique())\n",
        "    product_mapping = {prod: position for position, prod in enumerate(distinct_products)}\n",
        "    transactions_df[\"product_id\"] = transactions_df[\"StockCode\"].map(product_mapping)\n",
        "\n",
        "    # Invoice/session encoding\n",
        "    transactions_df[\"InvoiceNo\"] = transactions_df[\"InvoiceNo\"].astype(str)\n",
        "    distinct_invoices = pd.Series(transactions_df[\"InvoiceNo\"].unique())\n",
        "    invoice_mapping = {invoice: position for position, invoice in enumerate(distinct_invoices)}\n",
        "    transactions_df[\"basket_id\"] = transactions_df[\"InvoiceNo\"].map(invoice_mapping)\n",
        "\n",
        "    # Remove duplicate product-basket pairs\n",
        "    unique_pairs = transactions_df.drop_duplicates(subset=[\"basket_id\", \"product_id\"])\n",
        "\n",
        "    # Build sparse matrix representation\n",
        "    row_indices = unique_pairs[\"product_id\"].to_numpy(dtype=np.int32)\n",
        "    col_indices = unique_pairs[\"basket_id\"].to_numpy(dtype=np.int32)\n",
        "    values = (np.ones_like(row_indices, dtype=np.int8)).astype(np.int8)\n",
        "\n",
        "    total_products = len(distinct_products)\n",
        "    total_baskets = len(distinct_invoices)\n",
        "\n",
        "    product_basket_matrix = sparse.csr_matrix((values, (row_indices, col_indices)),\n",
        "                                              shape=(total_products, total_baskets),\n",
        "                                              dtype=np.int32)\n",
        "\n",
        "    # Extract product metadata\n",
        "    product_metadata: Dict[int, Dict] = {}\n",
        "    for product_idx, group_data in transactions_df.groupby(\"product_id\"):\n",
        "        desc_value = group_data[\"Description\"].mode().iloc[0] if \"Description\" in group_data else \"\"\n",
        "        product_metadata[int(product_idx)] = {\n",
        "            \"stock_code\": group_data[\"StockCode\"].iloc[0],\n",
        "            \"description\": str(desc_value)\n",
        "        }\n",
        "\n",
        "    return product_basket_matrix, product_metadata, total_baskets"
      ],
      "metadata": {
        "id": "KsJvEFZUwfwK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_scipy_to_cupy_sparse(scipy_matrix: sparse.csr_matrix):\n",
        "    \"\"\"Transfer sparse matrix from CPU (SciPy) to GPU (CuPy)\"\"\"\n",
        "    coo_format = scipy_matrix.tocoo()\n",
        "    gpu_data = cp.asarray(coo_format.data, dtype=cp.float32)\n",
        "    gpu_rows = cp.asarray(coo_format.row)\n",
        "    gpu_cols = cp.asarray(coo_format.col)\n",
        "    gpu_coo_matrix = cpx_sparse.coo_matrix((gpu_data, (gpu_rows, gpu_cols)), shape=scipy_matrix.shape)\n",
        "    return gpu_coo_matrix.tocsr()"
      ],
      "metadata": {
        "id": "oA7KH1PWwowJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_similarities_gpu_batched(product_matrix_gpu, top_k: int, batch_count: int = 64):\n",
        "    \"\"\"Compute top-K similar products using GPU acceleration with batching\"\"\"\n",
        "    total_products = int(product_matrix_gpu.shape[0])\n",
        "\n",
        "    # Calculate product frequency (diagonal elements)\n",
        "    diagonal_values_gpu = product_matrix_gpu.multiply(product_matrix_gpu).sum(axis=1).ravel().astype(cp.int32)\n",
        "    diagonal_values_cpu = cp.asnumpy(diagonal_values_gpu)\n",
        "\n",
        "    top_indices_collection = [None] * total_products\n",
        "    top_scores_collection = [None] * total_products\n",
        "\n",
        "    computation_start = time.time()\n",
        "    sqrt_diagonal_gpu = cp.sqrt(cp.maximum(diagonal_values_gpu.astype(cp.float32), 1.0))\n",
        "    product_indices = np.arange(total_products, dtype=np.int32)\n",
        "\n",
        "    for batch_start in range(0, total_products, batch_count):\n",
        "        batch_end = min(batch_start + batch_count, total_products)\n",
        "        current_batch = product_indices[batch_start:batch_end]\n",
        "        batch_length = len(current_batch)\n",
        "\n",
        "        # Extract batch rows and compute cooccurrence matrix\n",
        "        batch_matrix = product_matrix_gpu[current_batch, :]\n",
        "        cooccurrence_batch = batch_matrix.dot(product_matrix_gpu.T)\n",
        "        cooccurrence_dense = cooccurrence_batch.toarray().astype(cp.float32)\n",
        "\n",
        "        denominator_matrix = sqrt_diagonal_gpu[cp.asarray(current_batch, dtype=cp.int32)].astype(cp.float32)[:, None] * sqrt_diagonal_gpu[None, :]\n",
        "\n",
        "        similarity_batch = cp.where(denominator_matrix > 0.0,\n",
        "                                    cooccurrence_dense / denominator_matrix,\n",
        "                                    0.0).astype(cp.float32)\n",
        "\n",
        "        # Zero out self-similarities\n",
        "        similarity_batch[cp.arange(batch_length, dtype=cp.int32),\n",
        "                        cp.asarray(current_batch, dtype=cp.int32)] = 0.0\n",
        "\n",
        "        # Extract top-K per row\n",
        "        if top_k >= total_products:\n",
        "            top_k_indices = cp.argsort(-similarity_batch, axis=1)[:, :top_k]\n",
        "            top_k_scores = cp.take_along_axis(similarity_batch, top_k_indices, axis=1)\n",
        "        else:\n",
        "            partition_indices = cp.argpartition(-similarity_batch, top_k, axis=1)[:, :top_k]\n",
        "            partition_scores = cp.take_along_axis(similarity_batch, partition_indices, axis=1)\n",
        "            sort_order = cp.argsort(-partition_scores, axis=1)\n",
        "            top_k_indices = cp.take_along_axis(partition_indices, sort_order, axis=1)\n",
        "            top_k_scores = cp.take_along_axis(partition_scores, sort_order, axis=1)\n",
        "\n",
        "        # Transfer results to CPU\n",
        "        top_k_indices_cpu = cp.asnumpy(top_k_indices.astype(cp.int32))\n",
        "        top_k_scores_cpu = cp.asnumpy(top_k_scores.astype(cp.float32))\n",
        "\n",
        "        for local_index in range(batch_length):\n",
        "            global_product = int(current_batch[local_index])\n",
        "            top_indices_collection[global_product] = top_k_indices_cpu[local_index].astype(np.int32)\n",
        "            top_scores_collection[global_product] = top_k_scores_cpu[local_index].astype(np.float32)\n",
        "\n",
        "        elapsed_time = time.time() - computation_start\n",
        "        print(f\"[GPU processing] batch {batch_start}-{batch_end-1} complete (size={batch_length}), time={elapsed_time:.2f}s\")\n",
        "\n",
        "    total_gpu_time = time.time() - computation_start\n",
        "    return top_indices_collection, top_scores_collection, diagonal_values_cpu, total_gpu_time"
      ],
      "metadata": {
        "id": "Z0ze2vkFw1mt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarities_cpu_baseline(product_matrix_scipy, top_k: int):\n",
        "    \"\"\"Baseline CPU implementation for similarity computation\"\"\"\n",
        "    total_products = product_matrix_scipy.shape[0]\n",
        "    diagonal_values = product_matrix_scipy.multiply(product_matrix_scipy).sum(axis=1).A1.astype(np.int32)\n",
        "    top_indices_collection = [None] * total_products\n",
        "    top_scores_collection = [None] * total_products\n",
        "\n",
        "    computation_start = time.time()\n",
        "    for product_id in range(total_products):\n",
        "        product_vector = product_matrix_scipy.getrow(product_id)\n",
        "        cooccurrence_vector = product_vector.dot(product_matrix_scipy.T)\n",
        "        cooccurrence_array = cooccurrence_vector.toarray().ravel().astype(np.float32)\n",
        "\n",
        "        denominator = math.sqrt(diagonal_values[product_id]) * np.sqrt(np.maximum(diagonal_values, 1.0))\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            similarity_vector = np.where(denominator > 0,\n",
        "                                        cooccurrence_array / denominator,\n",
        "                                        0.0).astype(np.float32)\n",
        "        similarity_vector[product_id] = 0.0\n",
        "\n",
        "        if top_k >= similarity_vector.size:\n",
        "            sorted_indices = np.argsort(-similarity_vector)[:top_k]\n",
        "        else:\n",
        "            partition = np.argpartition(-similarity_vector, top_k)[:top_k]\n",
        "            sorted_indices = partition[np.argsort(-similarity_vector[partition])]\n",
        "\n",
        "        top_indices_collection[product_id] = sorted_indices.astype(np.int32)\n",
        "        top_scores_collection[product_id] = similarity_vector[sorted_indices].astype(np.float32)\n",
        "\n",
        "        if (product_id + 1) % 500 == 0 or (product_id + 1) == total_products:\n",
        "            elapsed_time = time.time() - computation_start\n",
        "            print(f\"[CPU processing] {product_id+1}/{total_products} products done, time={elapsed_time:.2f}s\")\n",
        "\n",
        "    total_cpu_time = time.time() - computation_start\n",
        "    return top_indices_collection, top_scores_collection, diagonal_values, total_cpu_time"
      ],
      "metadata": {
        "id": "dgoEsj1Yw6s9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_recommendation_report(reference_product: int, top_indices_list: List[np.ndarray],\n",
        "                                  top_scores_list: List[np.ndarray],\n",
        "                                  product_matrix_scipy: sparse.csr_matrix,\n",
        "                                  diagonal_values: np.ndarray,\n",
        "                                  product_metadata: Dict[int, Dict],\n",
        "                                  total_baskets: int) -> pd.DataFrame:\n",
        "    \"\"\"Generate detailed recommendation report for a reference product\"\"\"\n",
        "    cooccurrence_vector = product_matrix_scipy.getrow(reference_product).dot(product_matrix_scipy.T)\n",
        "    cooccurrence_array = cooccurrence_vector.toarray().ravel().astype(np.int32)\n",
        "    denominator = math.sqrt(diagonal_values[reference_product]) * np.sqrt(np.maximum(diagonal_values, 1.0))\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        similarity_exact = np.where(denominator > 0.0,\n",
        "                                    cooccurrence_array.astype(np.float32) / denominator,\n",
        "                                    0.0).astype(np.float32)\n",
        "    similarity_exact[reference_product] = 0.0\n",
        "\n",
        "    recommended_indices = top_indices_list[reference_product]\n",
        "    report_rows = []\n",
        "    for position, related_product in enumerate(recommended_indices, start=1):\n",
        "        cooccurrence_count = int(cooccurrence_array[int(related_product)])\n",
        "        similarity_score = float(similarity_exact[int(related_product)])\n",
        "        lift_value = 0.0\n",
        "        if diagonal_values[reference_product] > 0 and diagonal_values[int(related_product)] > 0:\n",
        "            prob_both = cooccurrence_count / float(total_baskets)\n",
        "            prob_reference = diagonal_values[reference_product] / float(total_baskets)\n",
        "            prob_related = diagonal_values[int(related_product)] / float(total_baskets)\n",
        "            lift_value = prob_both / (prob_reference * prob_related) if (prob_reference * prob_related) > 0 else 0.0\n",
        "        report_rows.append({\n",
        "            \"rank\": position,\n",
        "            \"item_index\": int(related_product),\n",
        "            \"stock_code\": product_metadata[int(related_product)][\"stock_code\"] if int(related_product) in product_metadata else \"\",\n",
        "            \"description\": product_metadata[int(related_product)][\"description\"] if int(related_product) in product_metadata else \"\",\n",
        "            \"cooccurrence\": cooccurrence_count,\n",
        "            \"similarity\": similarity_score,\n",
        "            \"lift\": lift_value,\n",
        "            \"sessions_with_other\": int(diagonal_values[int(related_product)])\n",
        "        })\n",
        "    return pd.DataFrame(report_rows)"
      ],
      "metadata": {
        "id": "DQnpa07Aw_9x"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_performance_comparison(cpu_duration, gpu_transfer_time, gpu_compute_time):\n",
        "    \"\"\"Create visualization comparing CPU and GPU performance\"\"\"\n",
        "    gpu_combined = gpu_transfer_time + gpu_compute_time\n",
        "    category_labels = [\"CPU (SciPy) computation\", \"GPU data transfer\", \"GPU computation\", \"GPU combined\"]\n",
        "    duration_values = [cpu_duration, gpu_transfer_time, gpu_compute_time, gpu_combined]\n",
        "    plt.figure(figsize=(8,4))\n",
        "    bar_chart = plt.bar(category_labels, duration_values)\n",
        "    plt.ylabel(\"Execution Time (seconds)\")\n",
        "    plt.title(\"Performance Analysis: CPU vs GPU\")\n",
        "    for bar in bar_chart:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.3,\n",
        "                f\"{height:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NkUlcUg8xLDi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(argv=None):\n",
        "    argument_parser = argparse.ArgumentParser()\n",
        "    argument_parser.add_argument(\"--csv\", type=str, default=\"OnlineRetail_cached.csv\", help=\"Input CSV file path\")\n",
        "    argument_parser.add_argument(\"--k\", type=int, default=10, help=\"Number of top recommendations\")\n",
        "    argument_parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size for GPU processing\")\n",
        "    argument_parser.add_argument(\"--anchor_by\", choices=[\"most_popular\",\"random\",\"id\"], default=\"most_popular\")\n",
        "    argument_parser.add_argument(\"--anchor_id\", type=int, default=None)\n",
        "    argument_parser.add_argument(\"--country\", type=str, default=None)\n",
        "    argument_parser.add_argument(\"--save_all\", action=\"store_true\", help=\"Export complete recommendation datasets\")\n",
        "    argument_parser.add_argument(\"--inline_plot\", action=\"store_true\", help=\"Display performance visualization inline\")\n",
        "    config = argument_parser.parse_args(argv)\n",
        "\n",
        "    input_file = config.csv\n",
        "    recommendations_count = config.k\n",
        "    processing_batch_size = config.batch_size\n",
        "\n",
        "    print(\"Phase 1: Loading and preprocessing transaction dataset.\")\n",
        "    start_timestamp = time.time()\n",
        "    product_basket_matrix_cpu, product_metadata, total_baskets = parse_transaction_data(input_file, region=config.country)\n",
        "    end_timestamp = time.time()\n",
        "    print(f\" Dataset loaded: products={product_basket_matrix_cpu.shape[0]}, baskets={product_basket_matrix_cpu.shape[1]}, duration={end_timestamp-start_timestamp:.2f}s\")\n",
        "\n",
        "    print(\"\\nPhase 2: Transferring sparse matrix to GPU memory.\")\n",
        "    start_timestamp = time.time()\n",
        "    product_basket_matrix_gpu = convert_scipy_to_cupy_sparse(product_basket_matrix_cpu)\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    transfer_duration = time.time() - start_timestamp\n",
        "    print(f\" Transfer completed: {transfer_duration:.2f}s\")\n",
        "\n",
        "    print(\"\\nPhase 3: Computing recommendations using GPU (batched processing).\")\n",
        "    start_timestamp = time.time()\n",
        "    gpu_top_indices, gpu_top_scores, gpu_diagonal, gpu_compute_duration = compute_similarities_gpu_batched(\n",
        "        product_basket_matrix_gpu, top_k=recommendations_count, batch_count=processing_batch_size)\n",
        "    gpu_total_duration = transfer_duration + gpu_compute_duration\n",
        "    print(f\" GPU execution (transfer+compute): {gpu_total_duration:.2f}s (compute only: {gpu_compute_duration:.2f}s)\")\n",
        "\n",
        "    print(\"\\nPhase 4: Computing recommendations using CPU (baseline reference).\")\n",
        "    cpu_top_indices, cpu_top_scores, cpu_diagonal, cpu_duration = compute_similarities_cpu_baseline(\n",
        "        product_basket_matrix_cpu, top_k=recommendations_count)\n",
        "    print(f\" CPU execution duration: {cpu_duration:.2f}s\")\n",
        "\n",
        "    # Select reference product for demonstration\n",
        "    if config.anchor_by == \"most_popular\":\n",
        "        reference_product = int(np.argmax(cpu_diagonal))\n",
        "    elif config.anchor_by == \"random\":\n",
        "        reference_product = int(np.random.default_rng(1).integers(0, product_basket_matrix_cpu.shape[0]))\n",
        "    else:\n",
        "        if config.anchor_id is None:\n",
        "            raise ValueError(\"Must specify anchor_id when using anchor_by='id'\")\n",
        "        reference_product = config.anchor_id\n",
        "\n",
        "    reference_stock_code = product_metadata[reference_product]['stock_code']\n",
        "    reference_description = product_metadata[reference_product]['description']\n",
        "\n",
        "    print(f\"\\nReference product: index={reference_product}; \"\n",
        "          f\"stock_code={reference_stock_code}; \"\n",
        "          f\"description={reference_description}; \"\n",
        "          f\"basket_occurrences={int(cpu_diagonal[reference_product])}\")\n",
        "\n",
        "    # Generate recommendation reports\n",
        "    gpu_recommendations = generate_recommendation_report(reference_product, gpu_top_indices, gpu_top_scores,\n",
        "                                                        product_basket_matrix_cpu, gpu_diagonal,\n",
        "                                                        product_metadata, total_baskets)\n",
        "    cpu_recommendations = generate_recommendation_report(reference_product, cpu_top_indices, cpu_top_scores,\n",
        "                                                        product_basket_matrix_cpu, cpu_diagonal,\n",
        "                                                        product_metadata, total_baskets)\n",
        "\n",
        "    print(\"\\nRecommendations (GPU-generated):\")\n",
        "    print(gpu_recommendations.to_string(index=False))\n",
        "\n",
        "    print(\"\\nRecommendations (CPU-generated):\")\n",
        "    print(cpu_recommendations.to_string(index=False))\n",
        "\n",
        "    # Display sample recommendations for top products\n",
        "    try:\n",
        "        top_two_products = list(np.argsort(-cpu_diagonal)[:2])\n",
        "        print(f\"\\n\\n=== Sample recommendations for top 2 products (indices): {top_two_products} ===\")\n",
        "        for sample_product in top_two_products:\n",
        "            sample_stock = product_metadata[sample_product]['stock_code']\n",
        "            sample_desc = product_metadata[sample_product]['description']\n",
        "            print(f\"\\nSample Product {sample_product} (stock_code={sample_stock}, description={sample_desc}, baskets={int(cpu_diagonal[sample_product])})\")\n",
        "            sample_gpu_recs = generate_recommendation_report(sample_product, gpu_top_indices, gpu_top_scores,\n",
        "                                                            product_basket_matrix_cpu, gpu_diagonal,\n",
        "                                                            product_metadata, total_baskets)\n",
        "            sample_cpu_recs = generate_recommendation_report(sample_product, cpu_top_indices, cpu_top_scores,\n",
        "                                                            product_basket_matrix_cpu, cpu_diagonal,\n",
        "                                                            product_metadata, total_baskets)\n",
        "            print(\"\\nGPU recommendations (top 5):\")\n",
        "            print(sample_gpu_recs.head(5).to_string(index=False))\n",
        "            print(\"\\nCPU recommendations (top 5):\")\n",
        "            print(sample_cpu_recs.head(5).to_string(index=False))\n",
        "    except Exception as error:\n",
        "        print(\"Unable to generate sample recommendations:\", error)\n",
        "\n",
        "    if config.save_all:\n",
        "        print(\"\\nExporting complete recommendation datasets. This may take time for large catalogs.\")\n",
        "        # CPU results export\n",
        "        all_cpu_rows = []\n",
        "        for prod_idx in range(len(cpu_top_indices)):\n",
        "            indices = cpu_top_indices[prod_idx]\n",
        "            scores = cpu_top_scores[prod_idx]\n",
        "            for rank_pos, (related_idx, score_val) in enumerate(zip(indices, scores), start=1):\n",
        "                all_cpu_rows.append({\n",
        "                    \"item_index\": prod_idx,\n",
        "                    \"stock_code_item\": product_metadata[prod_idx][\"stock_code\"],\n",
        "                    \"item_description\": product_metadata[prod_idx][\"description\"],\n",
        "                    \"rank\": rank_pos,\n",
        "                    \"other_index\": int(related_idx),\n",
        "                    \"other_stock_code\": product_metadata[int(related_idx)][\"stock_code\"],\n",
        "                    \"other_description\": product_metadata[int(related_idx)][\"description\"],\n",
        "                    \"similarity\": float(score_val),\n",
        "                })\n",
        "        pd.DataFrame(all_cpu_rows).to_csv(\"recommendations_complete_cpu.csv\", index=False)\n",
        "        # GPU results export\n",
        "        all_gpu_rows = []\n",
        "        for prod_idx in range(len(gpu_top_indices)):\n",
        "            indices = gpu_top_indices[prod_idx]\n",
        "            scores = gpu_top_scores[prod_idx]\n",
        "            for rank_pos, (related_idx, score_val) in enumerate(zip(indices, scores), start=1):\n",
        "                all_gpu_rows.append({\n",
        "                    \"item_index\": prod_idx,\n",
        "                    \"stock_code_item\": product_metadata[prod_idx][\"stock_code\"],\n",
        "                    \"item_description\": product_metadata[prod_idx][\"description\"],\n",
        "                    \"rank\": rank_pos,\n",
        "                    \"other_index\": int(related_idx),\n",
        "                    \"other_stock_code\": product_metadata[int(related_idx)][\"stock_code\"],\n",
        "                    \"other_description\": product_metadata[int(related_idx)][\"description\"],\n",
        "                    \"similarity\": float(score_val),\n",
        "                })\n",
        "        pd.DataFrame(all_gpu_rows).to_csv(\"recommendations_complete_gpu.csv\", index=False)\n",
        "        print(\"Exported recommendations_complete_cpu.csv and recommendations_complete_gpu.csv\")\n",
        "\n",
        "    # Performance summary\n",
        "    print(\"\\nPERFORMANCE SUMMARY:\")\n",
        "    summary_data = pd.DataFrame([\n",
        "        {\"computation_method\": \"CPU (SciPy) row-wise\", \"execution_time_sec\": round(cpu_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) data transfer\", \"execution_time_sec\": round(transfer_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) computation\", \"execution_time_sec\": round(gpu_compute_duration, 3)},\n",
        "        {\"computation_method\": \"GPU (CuPy) combined\", \"execution_time_sec\": round(gpu_total_duration, 3)}\n",
        "    ])\n",
        "    speedup_factor = (cpu_duration / gpu_total_duration) if (gpu_total_duration > 0) else float('nan')\n",
        "    summary_display = summary_data.copy()\n",
        "    if not np.isnan(speedup_factor):\n",
        "        summary_display.loc[len(summary_display)] = {\n",
        "            \"computation_method\": \"Speedup (CPU/GPU)\",\n",
        "            \"execution_time_sec\": round(speedup_factor, 3)\n",
        "        }\n",
        "    print(summary_display.to_string(index=False))\n",
        "\n",
        "    # Visualization\n",
        "    if config.inline_plot:\n",
        "        try:\n",
        "            visualize_performance_comparison(cpu_duration, transfer_duration, gpu_compute_duration)\n",
        "        except Exception as error:\n",
        "            print(\"Warning: inline visualization failed:\", error)\n",
        "    else:\n",
        "        try:\n",
        "            from matplotlib import pyplot as plot_module\n",
        "            gpu_combined = transfer_duration + gpu_compute_duration\n",
        "            plot_data = pd.DataFrame([\n",
        "                {\"computation_method\": \"CPU (SciPy) row-wise\", \"execution_time_sec\": cpu_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) data transfer\", \"execution_time_sec\": transfer_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) computation\", \"execution_time_sec\": gpu_compute_duration},\n",
        "                {\"computation_method\": \"GPU (CuPy) combined\", \"execution_time_sec\": gpu_combined}\n",
        "            ])\n",
        "            plot_module.figure(figsize=(8, 4))\n",
        "            bar_plot = plot_module.bar(plot_data[\"computation_method\"], plot_data[\"execution_time_sec\"])\n",
        "            plot_module.ylabel(\"Execution Time (seconds)\")\n",
        "            plot_module.title(\"Performance Comparison: CPU vs GPU\")\n",
        "            for bar in bar_plot:\n",
        "                height = bar.get_height()\n",
        "                plot_module.text(bar.get_x() + bar.get_width()/2, height + 0.5,\n",
        "                               f\"{height:.2f}s\", ha='center', va='bottom', fontsize=9)\n",
        "            plot_module.tight_layout()\n",
        "            plot_module.savefig(\"performance_analysis.png\", dpi=150)\n",
        "            plot_module.close()\n",
        "            print(\"Performance visualization saved: performance_analysis.png\")\n",
        "        except Exception as error:\n",
        "            print(\"Warning: visualization generation failed:\", error)\n",
        "    print(\"\\nExecution completed successfully.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if hasattr(sys, 'argv') and len(sys.argv) > 0 and \\\n",
        "       (sys.argv[0].endswith('ipykernel_launcher.py') or sys.argv[0].endswith('colab_kernel_launcher.py')):\n",
        "        main(argv=[])\n",
        "    else:\n",
        "        main(argv=sys.argv[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYxT8Gm_tZan",
        "outputId": "15427028-1de4-44f6-9bcb-dec5d0802088"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Loading and preprocessing transaction dataset.\n",
            " Dataset loaded: products=3922, baskets=19960, duration=2.14s\n",
            "\n",
            "Phase 2: Transferring sparse matrix to GPU memory.\n",
            " Transfer completed: 0.03s\n",
            "\n",
            "Phase 3: Computing recommendations using GPU (batched processing).\n",
            "[GPU processing] batch 0-63 complete (size=64), time=0.02s\n",
            "[GPU processing] batch 64-127 complete (size=64), time=0.04s\n",
            "[GPU processing] batch 128-191 complete (size=64), time=0.06s\n",
            "[GPU processing] batch 192-255 complete (size=64), time=0.08s\n",
            "[GPU processing] batch 256-319 complete (size=64), time=0.12s\n",
            "[GPU processing] batch 320-383 complete (size=64), time=0.14s\n",
            "[GPU processing] batch 384-447 complete (size=64), time=0.16s\n",
            "[GPU processing] batch 448-511 complete (size=64), time=0.17s\n",
            "[GPU processing] batch 512-575 complete (size=64), time=0.23s\n",
            "[GPU processing] batch 576-639 complete (size=64), time=0.27s\n",
            "[GPU processing] batch 640-703 complete (size=64), time=0.32s\n",
            "[GPU processing] batch 704-767 complete (size=64), time=0.36s\n",
            "[GPU processing] batch 768-831 complete (size=64), time=0.41s\n",
            "[GPU processing] batch 832-895 complete (size=64), time=0.42s\n",
            "[GPU processing] batch 896-959 complete (size=64), time=0.44s\n",
            "[GPU processing] batch 960-1023 complete (size=64), time=0.46s\n",
            "[GPU processing] batch 1024-1087 complete (size=64), time=0.48s\n",
            "[GPU processing] batch 1088-1151 complete (size=64), time=0.49s\n",
            "[GPU processing] batch 1152-1215 complete (size=64), time=0.51s\n",
            "[GPU processing] batch 1216-1279 complete (size=64), time=0.52s\n",
            "[GPU processing] batch 1280-1343 complete (size=64), time=0.53s\n",
            "[GPU processing] batch 1344-1407 complete (size=64), time=0.54s\n",
            "[GPU processing] batch 1408-1471 complete (size=64), time=0.56s\n",
            "[GPU processing] batch 1472-1535 complete (size=64), time=0.57s\n",
            "[GPU processing] batch 1536-1599 complete (size=64), time=0.58s\n",
            "[GPU processing] batch 1600-1663 complete (size=64), time=0.59s\n",
            "[GPU processing] batch 1664-1727 complete (size=64), time=0.60s\n",
            "[GPU processing] batch 1728-1791 complete (size=64), time=0.61s\n",
            "[GPU processing] batch 1792-1855 complete (size=64), time=0.62s\n",
            "[GPU processing] batch 1856-1919 complete (size=64), time=0.64s\n",
            "[GPU processing] batch 1920-1983 complete (size=64), time=0.65s\n",
            "[GPU processing] batch 1984-2047 complete (size=64), time=0.66s\n",
            "[GPU processing] batch 2048-2111 complete (size=64), time=0.67s\n",
            "[GPU processing] batch 2112-2175 complete (size=64), time=0.68s\n",
            "[GPU processing] batch 2176-2239 complete (size=64), time=0.69s\n",
            "[GPU processing] batch 2240-2303 complete (size=64), time=0.70s\n",
            "[GPU processing] batch 2304-2367 complete (size=64), time=0.71s\n",
            "[GPU processing] batch 2368-2431 complete (size=64), time=0.72s\n",
            "[GPU processing] batch 2432-2495 complete (size=64), time=0.73s\n",
            "[GPU processing] batch 2496-2559 complete (size=64), time=0.74s\n",
            "[GPU processing] batch 2560-2623 complete (size=64), time=0.75s\n",
            "[GPU processing] batch 2624-2687 complete (size=64), time=0.76s\n",
            "[GPU processing] batch 2688-2751 complete (size=64), time=0.77s\n",
            "[GPU processing] batch 2752-2815 complete (size=64), time=0.78s\n",
            "[GPU processing] batch 2816-2879 complete (size=64), time=0.79s\n",
            "[GPU processing] batch 2880-2943 complete (size=64), time=0.80s\n",
            "[GPU processing] batch 2944-3007 complete (size=64), time=0.81s\n",
            "[GPU processing] batch 3008-3071 complete (size=64), time=0.81s\n",
            "[GPU processing] batch 3072-3135 complete (size=64), time=0.82s\n",
            "[GPU processing] batch 3136-3199 complete (size=64), time=0.83s\n",
            "[GPU processing] batch 3200-3263 complete (size=64), time=0.84s\n",
            "[GPU processing] batch 3264-3327 complete (size=64), time=0.85s\n",
            "[GPU processing] batch 3328-3391 complete (size=64), time=0.86s\n",
            "[GPU processing] batch 3392-3455 complete (size=64), time=0.88s\n",
            "[GPU processing] batch 3456-3519 complete (size=64), time=0.88s\n",
            "[GPU processing] batch 3520-3583 complete (size=64), time=0.89s\n",
            "[GPU processing] batch 3584-3647 complete (size=64), time=0.90s\n",
            "[GPU processing] batch 3648-3711 complete (size=64), time=0.91s\n",
            "[GPU processing] batch 3712-3775 complete (size=64), time=0.92s\n",
            "[GPU processing] batch 3776-3839 complete (size=64), time=0.93s\n",
            "[GPU processing] batch 3840-3903 complete (size=64), time=0.94s\n",
            "[GPU processing] batch 3904-3921 complete (size=18), time=0.95s\n",
            " GPU execution (transfer+compute): 0.98s (compute only: 0.95s)\n",
            "\n",
            "Phase 4: Computing recommendations using CPU (baseline reference).\n",
            "[CPU processing] 500/3922 products done, time=2.28s\n",
            "[CPU processing] 1000/3922 products done, time=4.61s\n",
            "[CPU processing] 1500/3922 products done, time=7.11s\n",
            "[CPU processing] 2000/3922 products done, time=9.38s\n",
            "[CPU processing] 2500/3922 products done, time=11.63s\n",
            "[CPU processing] 3000/3922 products done, time=13.88s\n",
            "[CPU processing] 3500/3922 products done, time=16.12s\n",
            "[CPU processing] 3922/3922 products done, time=18.31s\n",
            " CPU execution duration: 18.31s\n",
            "\n",
            "Reference product: index=0; stock_code=85123A; description=WHITE HANGING HEART T-LIGHT HOLDER; basket_occurrences=2198\n",
            "\n",
            "Recommendations (GPU-generated):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "Recommendations (CPU-generated):\n",
            " rank  item_index stock_code                        description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733   RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804    CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470              HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482  WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457    NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "    6         125      22469              HEART OF WICKER SMALL           376    0.231421 2.843005                 1201\n",
            "    7          55     82494L        WOODEN FRAME ANTIQUE WHITE            315    0.222729 3.143417                  910\n",
            "    8        1628      47566                      PARTY BUNTING           390    0.202652 2.101830                 1685\n",
            "    9         307      22219 LOVEBIRD HANGING DECORATION WHITE            212    0.193875 3.538912                  544\n",
            "   10         461      84836        ZINC METAL HEART DECORATION           210    0.193655 3.564498                  535\n",
            "\n",
            "\n",
            "=== Sample recommendations for top 2 products (indices): [np.int64(0), np.int64(138)] ===\n",
            "\n",
            "Sample Product 0 (stock_code=85123A, description=WHITE HANGING HEART T-LIGHT HOLDER, baskets=2198)\n",
            "\n",
            "GPU recommendations (top 5):\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "CPU recommendations (top 5):\n",
            " rank  item_index stock_code                       description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          58      21733  RED HANGING HEART T-LIGHT HOLDER           489    0.383165 5.992713                  741\n",
            "    2         256      22804   CANDLEHOLDER PINK HANGING HEART           336    0.329182 6.437152                  474\n",
            "    3         126      22470             HEART OF WICKER LARGE           342    0.239851 3.357509                  925\n",
            "    4          54      82482 WOODEN PICTURE FRAME WHITE FINISH           370    0.237953 3.054512                 1100\n",
            "    5         124      22457   NATURAL SLATE HEART CHALKBOARD            394    0.237794 2.864617                 1249\n",
            "\n",
            "Sample Product 138 (stock_code=85099B, description=JUMBO BAG RED RETROSPOT, baskets=2089)\n",
            "\n",
            "GPU recommendations (top 5):\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "\n",
            "CPU recommendations (top 5):\n",
            " rank  item_index stock_code                         description  cooccurrence  similarity     lift  sessions_with_other\n",
            "    1          59      22386             JUMBO BAG PINK POLKADOT           825    0.517203 6.471855                 1218\n",
            "    2          76      21931              JUMBO STORAGE BAG SUKI           724    0.460356 5.842638                 1184\n",
            "    3          81      22411   JUMBO SHOPPER VINTAGE RED PAISLEY           680    0.434031 5.529593                 1175\n",
            "    4          60     85099C      JUMBO  BAG BAROQUE BLACK WHITE           585    0.419031 5.990959                  933\n",
            "    5         773      21928 JUMBO BAG SCANDINAVIAN BLUE PAISLEY           541    0.416927 6.413341                  806\n",
            "\n",
            "PERFORMANCE SUMMARY:\n",
            "      computation_method  execution_time_sec\n",
            "    CPU (SciPy) row-wise              18.307\n",
            "GPU (CuPy) data transfer               0.027\n",
            "  GPU (CuPy) computation               0.948\n",
            "     GPU (CuPy) combined               0.975\n",
            "       Speedup (CPU/GPU)              18.768\n",
            "Performance visualization saved: performance_analysis.png\n",
            "\n",
            "Execution completed successfully.\n"
          ]
        }
      ]
    }
  ]
}